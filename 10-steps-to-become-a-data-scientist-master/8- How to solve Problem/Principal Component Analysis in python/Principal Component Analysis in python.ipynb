{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": " ## <div align=\"center\">  Principal Component Analysis in python </div>\n <div align=\"center\">**quite practical and far from any theoretical concepts**</div>\n<div style=\"text-align:center\">last update: <b>10/16/2018</b></div>"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "\n\n---------------------------------------------------------------------\nFork and Run this kernel on GitHub:\n> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\n\n-------------------------------------------------------------------------------------------------------------\n **I hope you find this kernel helpful and some UPVOTES would be very much appreciated**\n \n -----------\n"
    },
    {
      "metadata": {
        "_uuid": "5ceb839cb55e97e03757ef0438220e992e7ec994"
      },
      "cell_type": "markdown",
      "source": " <a id=\"0\"></a> <br>\n**Notebook Content**\n1. [Introduction](#1)\n1. [What is PCA Approach](#2)\n1. [How to Principal Component Analysis?](#3)\n1. [Reusable Principal Component Analysis](#4)\n1. [References](#5)\n"
    },
    {
      "metadata": {
        "_uuid": "752afdca7dfb022d9e095ffbea5cd6860c85be0b"
      },
      "cell_type": "markdown",
      "source": " <a id=\"1\"></a> <br>\n## 1- Introduction\n\nThe sheer size of data in the modern age is not only a challenge for computer hardware but also a main bottleneck for the performance of many machine learning algorithms. The main goal of a PCA analysis is to identify patterns in data; PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information.[3]\n"
    },
    {
      "metadata": {
        "_uuid": "425e80d2b093b81335a2e68dd772603917bc730a"
      },
      "cell_type": "markdown",
      "source": " <a id=\"2\"></a> <br>\n## 2- What is PCA Approach?\n\n1. Standardize the data.\n1. Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix, or perform Singular Vector Decomposition.\n1. Sort eigenvalues in descending order and choose the k eigenvectors that correspond to the k largest eigenvalues where k is the number of dimensions of the new feature subspace (k≤d)/.\n1. Construct the projection matrix W from the selected k eigenvectors.\n1. Transform the original dataset X via W to obtain a k-dimensional feature subspace Y."
    },
    {
      "metadata": {
        "_uuid": "d851cd0dd61d939dd68a0266baa303e862684589"
      },
      "cell_type": "markdown",
      "source": " <a id=\"3\"></a> <br>\n## 3- How to Principal Component Analysis?\nThere is no pca() function in NumPy, but we can easily calculate the Principal Component Analysis step-by-step using NumPy functions.\n\nThe example below defines a small 3×2 matrix, centers the data in the matrix, calculates the covariance matrix of the centered data, and then the eigendecomposition of the covariance matrix. The eigenvectors and eigenvalues are taken as the principal components and singular values and used to project the original data.[2]"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca7f95f946c669429f831b893dc0d7f36976aa12"
      },
      "cell_type": "code",
      "source": "from numpy import array\nfrom numpy import mean\nfrom numpy import cov\nfrom numpy.linalg import eig\n# define a matrix\nA = array([[1, 2], [3, 4], [5, 6]])\nprint(A)\n# calculate the mean of each column\nM = mean(A.T, axis=1)\nprint(M)\n# center columns by subtracting column means\nC = A - M\nprint(C)\n# calculate covariance matrix of centered matrix\nV = cov(C.T)\nprint(V)\n# eigendecomposition of covariance matrix\nvalues, vectors = eig(V)\nprint(vectors)\nprint(values)\n# project data\nP = vectors.T.dot(C.T)\nprint(P.T)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c91ddfa44dbd72725668c932b658a98eb57a9b94"
      },
      "cell_type": "markdown",
      "source": "Running the example first prints the original matrix, then the eigenvectors and eigenvalues of the centered covariance matrix, followed finally by the projection of the original matrix.\n\nInterestingly, we can see that only the first eigenvector is required, suggesting that we could project our 3×2 matrix onto a 3×1 matrix with little loss."
    },
    {
      "metadata": {
        "_uuid": "6305fa157fb5b41e6a300da17974167d537fdd52"
      },
      "cell_type": "markdown",
      "source": " <a id=\"4\"></a> <br>\n## 4- Reusable Principal Component Analysis\nWe can calculate a Principal Component Analysis on a dataset using the PCA() class in the scikit-learn library. The benefit of this approach is that once the projection is calculated, it can be applied to new data again and again quite easily.\n\nWhen creating the class, the number of components can be specified as a parameter.\n\nThe class is first fit on a dataset by calling the fit() function, and then the original dataset or other data can be projected into a subspace with the chosen number of dimensions by calling the transform() function.\n\nOnce fit, the eigenvalues and principal components can be accessed on the PCA class via the explained_variance_ and components_ attributes.\n\nThe example below demonstrates using this class by first creating an instance, fitting it on a 3×2 matrix, accessing the values and vectors of the projection, and transforming the original data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a9f8e12bdd29e95335b6c272a2a04e7ff3a21ac"
      },
      "cell_type": "code",
      "source": "# Principal Component Analysis\nfrom numpy import array\nfrom sklearn.decomposition import PCA\n# define a matrix\nA = array([[1, 2], [3, 4], [5, 6]])\nprint(A)\n# create the PCA instance\npca = PCA(2)\n# fit on data\npca.fit(A)\n# access values and vectors\nprint(pca.components_)\nprint(pca.explained_variance_)\n# transform data\nB = pca.transform(A)\nprint(B)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e74a0d39fe50f9ea7686b462bb51c187397bae4"
      },
      "cell_type": "markdown",
      "source": " <a id=\"5\"></a> <br>\n## 5- References\n1. [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n2. [calculate-principal-component-analysis-scratch-python](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/)\n3. [plot.ly](https://plot.ly/ipython-notebooks/principal-component-analysis/)"
    },
    {
      "metadata": {
        "_uuid": "51f7776da8f1d3f949b5fb595ba32a6cea179083"
      },
      "cell_type": "markdown",
      "source": "---------------------------------------------------------------------\nFork and Run this kernel on GitHub:\n> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\n \n\n-------------------------------------------------------------------------------------------------------------\n **I hope you find this kernel helpful and some UPVOTES would be very much appreciated**\n \n -----------"
    },
    {
      "metadata": {
        "_uuid": "088cd178c33c7b776d4cadceb14b70e40f9fde82"
      },
      "cell_type": "markdown",
      "source": "**Not completed yet!!!**\n\n**Update every two days**"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}