{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f9622945156d6337ba73c481da2de7efef7384"
   },
   "source": [
    "# <div style=\"text-align: center\">A Data Science Framework for Quora </div>\n",
    "\n",
    "<img src='http://s9.picofile.com/file/8342477368/kq.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "750903cc2679d39058f56df6c6c040be02b748df"
   },
   "source": [
    " <a id=\"1\"></a> <br>\n",
    "## 1- Introduction\n",
    "Quora has defined a competition in Kaggle. A realistic and attractive data set for data scientists.\n",
    "on this notebook, I will provide a comprehensive approach to solve Quora classification problem.\n",
    "I am open to getting your feedback for improving this **kernel**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cda11210a88d6484112cbe2c3624225328326c6a"
   },
   "source": [
    "## Notebook  Content\n",
    "1. [Introduction](#1)\n",
    "1. [Data Science Workflow for Quora](#2)\n",
    "1. [Problem Definition](#3)\n",
    "    1.[Problem feature](#4)\n",
    "    1.[Aim](#5)\n",
    "    1.[Variables](#6)\n",
    "    1. [ Inputs & Outputs](#7)\n",
    "    1. [Inputs ](#8)\n",
    "    1. [Outputs](#9)\n",
    "    1. [Exploratory data analysis](#16)\n",
    "1. [Data Collection](#17)\n",
    "1. [Model Deployment](#32)\n",
    "1. [Conclusion](#54)\n",
    "1. [References](#55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated**\n",
    " \n",
    " -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e11b73b618b0f6e4335520ef80267c6d577d1ba5"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 2- A Data Science Workflow for Quora\n",
    "Of course, the same solution can not be provided for all problems, so the best way is to create a general framework and adapt it to new problem.\n",
    "\n",
    "**You can see my workflow in the below image** :\n",
    "\n",
    " <img src=\"http://s9.picofile.com/file/8338227634/workflow.png\" />\n",
    "\n",
    "**you should\tfeel free\tto\tadapt \tthis\tchecklist \tto\tyour needs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "600be852c0d28e7c0c5ebb718904ab15a536342c"
   },
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## 3- Problem Definition\n",
    "I think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n",
    "**we will be predicting whether a question asked on Quora is sincere or not.**\n",
    "## 3-1 Business View \n",
    "An existential problem for any major website today is how to handle toxic and divisive content. **Quora** wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.\n",
    "\n",
    "**Quora** is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n",
    "\n",
    "In this kernel, I will develop models that identify and flag insincere questions.we Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.\n",
    "\n",
    "### 3-2 What is a insincere question?\n",
    "is defined as a question intended to make a statement rather than look for helpful answers.\n",
    "\n",
    "### 3-3 how can we find insincere question?\n",
    "Some characteristics that can signify that a question is insincere:\n",
    "\n",
    "1. Has a non-neutral tone\n",
    "    1. Has an exaggerated tone to underscore a point about a group of people\n",
    "    1. Is rhetorical and meant to imply a statement about a group of people\n",
    "1. Is disparaging or inflammatory\n",
    "    1. Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
    "    1. Makes disparaging attacks/insults against a specific person or group of people\n",
    "    1. Based on an outlandish premise about a group of people\n",
    "    1. Disparages against a characteristic that is not fixable and not measurable\n",
    "1. Isn't grounded in reality\n",
    "    1. Based on false information, or contains absurd assumptions\n",
    "    1. Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "## 4- Problem Feature\n",
    "Problem Definition has four steps that have illustrated in the picture below:\n",
    "\n",
    "1. Aim\n",
    "1. Variable\n",
    "1. Inputs & Outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"5\"></a> <br>\n",
    "### 4-1 Aim\n",
    "we will be predicting whether a question asked on Quora is sincere or not.\n",
    "\n",
    "\n",
    "<a id=\"6\"></a> <br>\n",
    "### 4-2 Variables\n",
    "\n",
    "1. qid - unique question identifier\n",
    "1. question_text - Quora question text\n",
    "1. target - a question labeled \"insincere\" has a value of 1, otherwise 0\n",
    "\n",
    "<a id=\"6\"></a> <br>\n",
    "### 4-3 Inputs & Outputs\n",
    "we use train.csv and test.csv as Input and we should upload a  submission.csv as Output\n",
    "\n",
    "\n",
    "**<< Note >>**\n",
    "> You must answer the following question:\n",
    "How does your company expact to use and benfit from your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbedcae8843986c2139f18dad4b5f313e6535ac5"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 5- Select Framework\n",
    "after problem definition and problem feature, we should select our framework To implement it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c90e261f3b150e10aaec1f34ab3be768acf7aa25"
   },
   "source": [
    "### 5-1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('Python: {}'.format(sys.version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "431bf889ae401c1089a13835356c13f2b6a06f6c"
   },
   "source": [
    "### 5-3 Setup\n",
    "\n",
    "A few tiny adjustments for better **code readability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "2a498652935827a033d0bcb7df1d28c068f44a25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04ff1a533119d589baee777c21194a951168b0c7"
   },
   "source": [
    "<a id=\"16\"></a> <br>\n",
    "## 6- EDA\n",
    " In this section, you'll learn how to use graphical and numerical techniques to begin uncovering the structure of your data. \n",
    " \n",
    "* Which variables suggest interesting relationships?\n",
    "* Which observations are unusual?\n",
    "* Analysis of the features!\n",
    "By the end of the section, you'll be able to answer these questions and more, while generating graphics that are both insightful and beautiful.  then We will review analytical and statistical operations:\n",
    "\n",
    "*   5-1 Data Collection\n",
    "*   5-2 Visualization\n",
    "*   5-3 Data Preprocessing\n",
    "*   5-4 Data Cleaning\n",
    "<img src=\"http://s9.picofile.com/file/8338476134/EDA.png\">\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cedecea930b278f86292367cc28d2996a235a169"
   },
   "source": [
    "<a id=\"17\"></a> <br>\n",
    "## 6-1 Data Collection\n",
    "**Data collection** is the process of gathering and measuring data, information or any variables of interest in a standardized and established manner that enables the collector to answer or test hypothesis and evaluate outcomes of the particular collection.[techopedia]\n",
    "\n",
    "I start Collection Data by the training and testing datasets into **Pandas DataFrames**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9269ae851b744856bce56840637030a16a5877e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train and test to play with it\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ed9c838069f54de5cf90b20a774c3e236149b3"
   },
   "source": [
    "**<< Note 1 >>**\n",
    "\n",
    "* Each **row** is an observation (also known as : sample, example, instance, record)\n",
    "* Each **column** is a feature (also known as: Predictor, attribute, Independent Variable, input, regressor, Covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b5fd1034cd591ebd29fba1c77d342ec2b408d13"
   },
   "source": [
    "After loading the data via **pandas**, we should checkout what the content is, description and via the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"target\"].value_counts()\n",
    "# data is imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = train['target'].values\n",
    "\n",
    "np.unique(train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "055772bd170aa8018aabd85106b76675802c33b3"
   },
   "source": [
    "<a id=\"18\"></a> <br>\n",
    "## 6-2 Visualization\n",
    "**Data visualization**  is the presentation of data in a pictorial or graphical format. It enables decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns.\n",
    "\n",
    "With interactive visualization, you can take the concept a step further by using technology to drill down into charts and graphs for more detail, interactively changing what data you see and how it’s processed.[SAS]\n",
    "\n",
    " In this section I show you  **11 plots** with **matplotlib** and **seaborn** that is listed in the blew picture:\n",
    " <img src=\"http://s8.picofile.com/file/8338475500/visualization.jpg\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0014a7a52e714996bc443981c853095926d20e5"
   },
   "source": [
    "<a id=\"19\"></a> <br>\n",
    "### 6-2-1 Scatter plot\n",
    "\n",
    "Scatter plot Purpose To identify the type of relationship (if any) between two quantitative variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af099546eed64ebc796403d4139cb4c977c27b03",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify the graph above by assigning each species an individual color.\n",
    "g = sns.FacetGrid(train, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n",
    "                  palette={1:\"seagreen\", 0:\"gray\"})\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1c7b62b5f8cba427bca13049256365141655372"
   },
   "source": [
    "<a id=\"20\"></a> <br>\n",
    "### 6-2-2 Box\n",
    "In descriptive statistics, a **box plot** or boxplot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles, hence the terms box-and-whisker plot and box-and-whisker diagram.[wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0655e20f31a582f861d391308a088778cd7eaae9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.plot(kind='box', subplots=True, layout=(2,4), sharex=False, sharey=False)\n",
    "plt.figure()\n",
    "#This gives us a much clearer idea of the distribution of the input attributes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f6426fd44bcd77d35a5fdbc8c4fc4f18d991ad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot the species data using a box plot:\n",
    "\n",
    "sns.boxplot(x=\"Fare\", y=\"Age\", data=test )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b193e4aa7e6fb337d3f65c334849094addd097a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Seaborn's striplot to add data points on top of the box plot \n",
    "# Insert jitter=True so that the data points remain scattered and not piled into a verticle line.\n",
    "# Assign ax to each axis, so that each plot is ontop of the previous axis. \n",
    "\n",
    "ax= sns.boxplot(x=\"Fare\", y=\"Age\", data=train)\n",
    "ax= sns.stripplot(x=\"Fare\", y=\"Age\", data=train, jitter=True, edgecolor=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56adbafa89c117118621c72b3b7cb19edc21298e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweek the plot above to change fill and border color color using ax.artists.\n",
    "# Assing ax.artists a variable name, and insert the box number into the corresponding brackets\n",
    "\n",
    "ax= sns.boxplot(x=\"Fare\", y=\"Age\", data=train)\n",
    "ax= sns.stripplot(x=\"Fare\", y=\"Age\", data=train, jitter=True, edgecolor=\"gray\")\n",
    "\n",
    "boxtwo = ax.artists[2]\n",
    "boxtwo.set_facecolor('red')\n",
    "boxtwo.set_edgecolor('black')\n",
    "boxthree=ax.artists[1]\n",
    "boxthree.set_facecolor('yellow')\n",
    "boxthree.set_edgecolor('black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "743a92c3c2fff1a1f99845518247f7971ad18b7c"
   },
   "source": [
    "<a id=\"21\"></a> <br>\n",
    "### 6-2-3 Histogram\n",
    "We can also create a **histogram** of each input variable to get an idea of the distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5da0520ed3e738ee8814b2d91843ed4acec2b6e6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "train.hist(figsize=(15,20))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4e3de19781686010c6038f0e3076eb678398169"
   },
   "source": [
    "It looks like perhaps two of the input variables have a Gaussian distribution. This is useful to note as we can use algorithms that can exploit this assumption.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f80a6e971cbf0af72d659b51af552ea1dddc9a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Age\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06c7ec477241ef4e5ea68e6cc09f785638b31d6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,10))\n",
    "train[train['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\n",
    "ax[0].set_title('Survived= 0')\n",
    "x1=list(range(0,85,5))\n",
    "ax[0].set_xticks(x1)\n",
    "train[train['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\n",
    "ax[1].set_title('Survived= 1')\n",
    "x2=list(range(0,85,5))\n",
    "ax[1].set_xticks(x2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18637e84198615d9f936d0ef62723a98aa8cf4a4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived',data=train,ax=ax[1])\n",
    "ax[1].set_title('Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4349021072da9bc4d1f1b523991e19590593d048",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Survived vs Sex')\n",
    "sns.countplot('Sex',hue='Survived',data=train,ax=ax[1])\n",
    "ax[1].set_title('Sex:Survived vs Dead')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bbff56707484f88625eb8ef309b712ba03f939e"
   },
   "source": [
    "<a id=\"22\"></a> <br>\n",
    "### 6-2-4 Multivariate Plots\n",
    "Now we can look at the interactions between the variables.\n",
    "\n",
    "First, let’s look at scatterplots of all pairs of attributes. This can be helpful to spot structured relationships between input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb4e5d117e4ef40d7668632f42130206a5537bd0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# scatter plot matrix\n",
    "pd.plotting.scatter_matrix(train,figsize=(10,10))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de7fea7986071fafbe0b93933e3beda445cbe373"
   },
   "source": [
    "Note the diagonal grouping of some pairs of attributes. This suggests a high correlation and a predictable relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0f696ec021ec99c1058a62e22c8b73082fe6fa7"
   },
   "source": [
    "<a id=\"23\"></a> <br>\n",
    "### 6-2-5 violinplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e352d2f8340609adf4bf6718b1d2ecee0fa730b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# violinplots on petal-length for each species\n",
    "sns.violinplot(data=train,x=\"Fare\", y=\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9a29b9689cd5c3901f27901aa0b5295fc2f04f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "sns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=train,split=True,ax=ax[0])\n",
    "ax[0].set_title('Pclass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10))\n",
    "sns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=train,split=True,ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ed35bceb87051e56316d35a630334518e8b8c64"
   },
   "source": [
    "<a id=\"24\"></a> <br>\n",
    "### 6-2-6 pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b80350add6f9a742f10bffc4b497562f8bebea95",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using seaborn pairplot to see the bivariate relation between each pair of features\n",
    "sns.pairplot(train, hue=\"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb187bcc0fb51e53f8abe9e3952c6ae5c3177411"
   },
   "source": [
    "From the plot, we can see that the species setosa is separataed from the other two across all feature combinations\n",
    "\n",
    "We can also replace the histograms shown in the diagonal of the pairplot by kde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5570ff32db5a4740b26b244531af552ac1b57f4a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updating the diagonal elements in a pairplot to show a kde\n",
    "sns.pairplot(train, hue=\"Age\",diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2544d3c2dd34a360d295019d8cb597c7ef8f66bc"
   },
   "source": [
    "<a id=\"25\"></a> <br>\n",
    "###  6-2-7 kdeplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d07222b89303b386e9e824d52cc73c045667f25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seaborn's kdeplot, plots univariate or bivariate density estimates.\n",
    "#Size can be changed by tweeking the value used\n",
    "sns.FacetGrid(train, hue=\"Survived\", size=5).map(sns.kdeplot, \"Fare\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "560d8e8f17bacefaf8c3855a9648f26b82fdee9b"
   },
   "source": [
    "<a id=\"26\"></a> <br>\n",
    "### 6-2-8 jointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4adb4da16ea61e0f1a12bc9925dfbbaaa81e0360",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use seaborn's jointplot to make a hexagonal bin plot\n",
    "#Set desired size and ratio and choose a color.\n",
    "sns.jointplot(x=\"Age\", y=\"Survived\", data=train, size=10,ratio=10, kind='hex',color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3768e31e990bfe4c2ff7b45087fbba85e0560d00"
   },
   "source": [
    "<a id=\"27\"></a> <br>\n",
    "###  6-2-9 andrews_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "263eaa9d2bfad0f8c68b6e8e874bdc11a6e802ac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will use seaborn jointplot shows bivariate scatterplots and univariate histograms with Kernel density \n",
    "# estimation in the same figure\n",
    "sns.jointplot(x=\"Age\", y=\"Fare\", data=train, size=6, kind='kde', color='#800000', space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e73333289d17dd648b7b2112d7fe3fe7ea444d0"
   },
   "source": [
    "<a id=\"28\"></a> <br>\n",
    "### 6-2-10 Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3100955ca9dc61ac7d435e9c064d10d06f26afa7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4)) \n",
    "sns.heatmap(train.corr(),annot=True,cmap='cubehelix_r') #draws  heatmap with input as the correlation matrix calculted by(iris.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc691cdb2001f0a7dc35b2f2644e4cf455e3016a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(train.corr(),annot=False,cmap='RdYlGn',linewidths=0.2)  \n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab06d1cd799430c7c7f8de978ee2c6e275e7655b"
   },
   "source": [
    "###  6-2-11 Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "329488de1a908a6d367b9da4b40a20238163d32e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Pclass'].value_counts().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3dafbfb8735b66c98088cb0e85d50d4772a06df1"
   },
   "source": [
    "### 6-2-12 Factorplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33f7dd81d408b1530113c451dc1b58194ec487b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot('Pclass','Survived',hue='Sex',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "739bba4248dec9a31b7f4f00618cd2fce103d172"
   },
   "source": [
    "### 6-2-13 distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "318b702bd9751c332c3ad854e7f90e685b1417f5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,3,figsize=(20,8))\n",
    "sns.distplot(train[train['Pclass']==1].Fare,ax=ax[0])\n",
    "ax[0].set_title('Fares in Pclass 1')\n",
    "sns.distplot(train[train['Pclass']==2].Fare,ax=ax[1])\n",
    "ax[1].set_title('Fares in Pclass 2')\n",
    "sns.distplot(train[train['Pclass']==3].Fare,ax=ax[2])\n",
    "ax[2].set_title('Fares in Pclass 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0859caf857ceeb19f4cc47ccd11fbbfdfe4b0dd9"
   },
   "source": [
    "**<< Note >>**\n",
    "\n",
    "**Yellowbrick** is a suite of visual diagnostic tools called “Visualizers” that extend the Scikit-Learn API to allow human steering of the model selection process. In a nutshell, Yellowbrick combines scikit-learn with matplotlib in the best tradition of the scikit-learn documentation, but to produce visualizations for your models! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5af51158a5bc342947c553392e3d1665ac24ba62"
   },
   "source": [
    "### 6-2-12 Conclusion\n",
    "we have used Python to apply data visualization tools to the Iris dataset. Color and size changes were made to the data points in scatterplots. I changed the border and fill color of the boxplot and violin, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91dda1f631cf4ed362162501aaaac6d19cfd6cc7"
   },
   "source": [
    "<a id=\"30\"></a> <br>\n",
    "## 7 Data Preprocessing\n",
    "**Data preprocessing** refers to the transformations applied to our data before feeding it to the algorithm.\n",
    " \n",
    "Data Preprocessing is a technique that is used to convert the raw data into a clean data set. In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis.\n",
    "there are plenty of steps for data preprocessing and we just listed some of them :\n",
    "* removing Target column (id)\n",
    "* Sampling (without replacement)\n",
    "* Making part of iris unbalanced and balancing (with undersampling and SMOTE)\n",
    "* Introducing missing values and treating them (replacing by average values)\n",
    "* Noise filtering\n",
    "* Data discretization\n",
    "* Normalization and standardization\n",
    "* PCA analysis\n",
    "* Feature selection (filter, embedded, wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "581b90e6a869c3793472c7edd59091d6d6342fb2"
   },
   "source": [
    "## 4-3-1 Features\n",
    "Features:\n",
    "* numeric\n",
    "* categorical\n",
    "* ordinal\n",
    "* datetime\n",
    "* coordinates\n",
    "\n",
    "find the type of features in titanic dataset\n",
    "<img src=\"http://s9.picofile.com/file/8339959442/titanic.png\" height=\"700\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73ab30f86273b590a51fc363d9bf78c2709558fa"
   },
   "source": [
    "### 4-3-2 Explorer Dataset\n",
    "1- Dimensions of the dataset.\n",
    "\n",
    "2- Peek at the data itself.\n",
    "\n",
    "3- Statistical summary of all attributes.\n",
    "\n",
    "4- Breakdown of the data by the class variable.[7]\n",
    "\n",
    "Don’t worry, each look at the data is **one command**. These are useful commands that you can use again and again on future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b45251be7be77333051fe738639104ae1005fa5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c64e9d3e0bf394fb833de94a0fc5c34f69fce24c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#columns*rows\n",
    "train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6315bf510cecb907b2d23aad25faf6ccad32ac4"
   },
   "source": [
    "how many NA elements in every column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "675f72fb58d83c527f71819e71ed8e17f81126f5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8e124ca20643ad307d9bfdc34328d548c6ddcbc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows that have NA's\n",
    "#train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "277e1998627d6a3ddeff4e913a6b8c3dc81dec96"
   },
   "source": [
    "\n",
    "We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property.\n",
    "\n",
    "You should see 150 instances and 5 attributes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95ee5e18f97bc410df1e54ac74e32cdff2b30755"
   },
   "source": [
    "for getting some information about the dataset you can use **info()** command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca840f02925751186f87e402fcb5f637ab1ab8a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3458838205be4c7fbff88e95ef69934e13e2199b"
   },
   "source": [
    "you see number of unique item for Species with command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b90d165a007106ae99809ad28edd75bd8153dd8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8accfbddf2228274ad412c3ad3be72b4107d6f6c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Pclass\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae08b544a8d4202c7d0a47ec83d685e81c91a66d"
   },
   "source": [
    "to check the first 5 rows of the data set, we can use head(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5899889553c3416b27e93efceddb106eb71f5156",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1150b6ac3d82562aefd5c64f9f01accee5eace4d"
   },
   "source": [
    "to check out last 5 row of the data set, we use tail() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79339442ff1f53ae1054d794337b9541295d3305",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c288c3dc8656a872a8529368812546e434d3a22"
   },
   "source": [
    "to pop up 5 random rows from the data set, we can use **sample(5)**  function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09eb18d1fcf4a2b73ba2f5ddce99dfa521681140",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.sample(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8a1cc36348c68fb98d6cb28aa9919fc5f2892f3"
   },
   "source": [
    "to give a statistical summary about the dataset, we can use **describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f7211e96627b9a81c5b620a9ba61446f7719ea3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "031d16ca235837e889734635ecff193be64b27a4"
   },
   "source": [
    "to check out how many null info are on the dataset, we can use **isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8807b632269e2fa734ad26e8513199400fc09a83",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "446e6162e16325213047ff31454813455668b574",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.groupby('Pclass').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2f1eaf0b6dfdc7cc4dace04614e99ed56425d00"
   },
   "source": [
    "to print dataset **columns**, we can use columns atribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "909d61b33ec06249d0842e6115597bbacf21163f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22bc5d81c18275ee1fb082c0adbb7a65bdbec4cc"
   },
   "source": [
    "**<< Note 2 >>**\n",
    "in pandas's data frame you can perform some query such as \"where\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8c8d9fd63d9bdb601183aeb4f1435affeb8a596",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.where(train ['Age']==30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33fc33a18489b438a884819d99dc00a02b113be8"
   },
   "source": [
    "as you can see in the below in python, it is so easy perform some query on the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8b545ff7e8367c5ab9c1db710f70b6936ac8422c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[train['Age']>7.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c92b300076a232321c915857d8a7c5685a97865",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperating the data into dependent and independent variables\n",
    "X = train.iloc[:, :-1].values\n",
    "y = train.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa882e5bcdc7d5f440489eff75d1d225269655a4"
   },
   "source": [
    "**<< Note >>**\n",
    ">**Preprocessing and generation pipelines depend on a model type**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8280749a19af32869978c61941d1dea306632d71"
   },
   "source": [
    "<a id=\"31\"></a> <br>\n",
    "## 8 Data Cleaning\n",
    "When dealing with real-world data, dirty data is the norm rather than the exception. We continuously need to predict correct values, impute missing ones, and find links between various data artefacts such as schemas and records. We need to stop treating data cleaning as a piecemeal exercise (resolving different types of errors in isolation), and instead leverage all signals and resources (such as constraints, available statistics, and dictionaries) to accurately predict corrective actions.\n",
    "\n",
    "The primary goal of data cleaning is to detect and remove errors and **anomalies** to increase the value of data in analytics and decision making. While it has been the focus of many researchers for several years, individual problems have been addressed separately. These include missing value imputation, outliers detection, transformations, integrity constraints violations detection and repair, consistent query answering, deduplication, and many other related problems such as profiling and constraints mining.[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60dcf563b3a637f4836d5d3487b15a8f444caf53",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns\n",
    "features = cols[0:12]\n",
    "labels = cols[4]\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72cc7c7b60a33390a85b16bc34e3b9e424650cdd"
   },
   "source": [
    "<a id=\"32\"></a> <br>\n",
    "## 9- Apply Learning\n",
    "In this section have been applied plenty of  ** learning algorithms** that play an important rule in your experiences and improve your knowledge in case of ML technique.\n",
    "\n",
    "> **<< Note 3 >>** : The results shown here may be slightly different for your analysis because, for example, the neural network algorithms use random number generators for fixing the initial value of the weights (starting points) of the neural networks, which often result in obtaining slightly different (local minima) solutions each time you run the analysis. Also note that changing the seed for the random number generator used to create the train, test, and validation samples can change your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b06cb1191a0f52a904c52a918d1f999536e79bda",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = train.iloc[:, :-1].values\n",
    "y = train.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d13f167dd92888d856c4ad2ff2895bf4855e361c"
   },
   "source": [
    "## Accuracy and precision\n",
    "* **precision** : \n",
    "\n",
    "In pattern recognition, information retrieval and binary classification, precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, \n",
    "* **recall** : \n",
    "\n",
    "recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. \n",
    "* **F-score** :\n",
    "\n",
    "the F1 score is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive). The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "**What is the difference between accuracy and precision?\n",
    "\"Accuracy\" and \"precision\" are general terms throughout science. A good way to internalize the difference are the common \"bullseye diagrams\". In machine learning/statistics as a whole, accuracy vs. precision is analogous to bias vs. variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8b544762cc789bfeb8ebccd6765f77b9c7e1a0f"
   },
   "source": [
    "<a id=\"33\"></a> <br>\n",
    "## 9-1 K-Nearest Neighbours\n",
    "In **Machine Learning**, the **k-nearest neighbors algorithm** (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n",
    "\n",
    "In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "In k-NN regression, the output is the property value for the object. This value is the average of the values of its k nearest neighbors.\n",
    "k-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until classification. The k-NN algorithm is among the simplest of all machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97adc471c068fbd8d36ca19a4db0d98b0924c731"
   },
   "source": [
    "-----------------\n",
    "<a id=\"54\"></a> <br>\n",
    "# 10- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1adfb5ba84e0f1d8fba58a2fca30546ead095047",
    "collapsed": true
   },
   "source": [
    "this kernel is not completed yet , I have tried to cover all the parts related to the process of **Quora problem** with a variety of Python packages and I know that there are still some problems then I hope to get your feedback to improve it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf3679a51c72dbe2d2549b5fe97e4ac5f1fa0fa0"
   },
   "source": [
    "you can Fork and Run this kernel on Github:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/Machine-Learning-Workflow-with-Python)\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "<a id=\"55\"></a> <br>\n",
    "\n",
    "-----------\n",
    "\n",
    "# 11- References\n",
    "1. [https://skymind.ai/wiki/machine-learning-workflow](https://skymind.ai/wiki/machine-learning-workflow)\n",
    "\n",
    "1. [Problem-define](https://machinelearningmastery.com/machine-learning-in-python-step-by-step/)\n",
    "\n",
    "1. [Sklearn](http://scikit-learn.org/)\n",
    "\n",
    "1. [machine-learning-in-python-step-by-step](https://machinelearningmastery.com/machine-learning-in-python-step-by-step/)\n",
    "\n",
    "1. [Data Cleaning](http://wp.sigmod.org/?p=2288)\n",
    "\n",
    "1. [competitive data science](https://www.coursera.org/learn/competitive-data-science/)\n",
    "\n",
    "1. [Machine Learning Certification by Stanford University (Coursera)](https://www.coursera.org/learn/machine-learning/)\n",
    "\n",
    "1. [Machine Learning A-Z™: Hands-On Python & R In Data Science (Udemy)](https://www.udemy.com/machinelearning/)\n",
    "\n",
    "1. [Deep Learning Certification by Andrew Ng from deeplearning.ai (Coursera)](https://www.coursera.org/specializations/deep-learning)\n",
    "\n",
    "1. [Python for Data Science and Machine Learning Bootcamp (Udemy)](Python for Data Science and Machine Learning Bootcamp (Udemy))\n",
    "\n",
    "1. [Mathematics for Machine Learning by Imperial College London](https://www.coursera.org/specializations/mathematics-machine-learning)\n",
    "\n",
    "1. [Deep Learning A-Z™: Hands-On Artificial Neural Networks](https://www.udemy.com/deeplearning/)\n",
    "\n",
    "1. [Complete Guide to TensorFlow for Deep Learning Tutorial with Python](https://www.udemy.com/complete-guide-to-tensorflow-for-deep-learning-with-python/)\n",
    "\n",
    "1. [Data Science and Machine Learning Tutorial with Python – Hands On](https://www.udemy.com/data-science-and-machine-learning-with-python-hands-on/)\n",
    "\n",
    "1. [Machine Learning Certification by University of Washington](https://www.coursera.org/specializations/machine-learning)\n",
    "\n",
    "1. [Data Science and Machine Learning Bootcamp with R](https://www.udemy.com/data-science-and-machine-learning-bootcamp-with-r/)\n",
    "\n",
    "1. [Creative Applications of Deep Learning with TensorFlow](https://www.class-central.com/course/kadenze-creative-applications-of-deep-learning-with-tensorflow-6679)\n",
    "\n",
    "1. [Neural Networks for Machine Learning](https://www.class-central.com/mooc/398/coursera-neural-networks-for-machine-learning)\n",
    "\n",
    "1. [Practical Deep Learning For Coders, Part 1](https://www.class-central.com/mooc/7887/practical-deep-learning-for-coders-part-1)\n",
    "\n",
    "1. [Machine Learning](https://www.cs.ox.ac.uk/teaching/courses/2014-2015/ml/index.html)\n",
    "\n",
    "1. [https://www.kaggle.com/ash316/eda-to-prediction-dietanic](https://www.kaggle.com/ash316/eda-to-prediction-dietanic)\n",
    "\n",
    "1. [https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic)\n",
    "\n",
    "1. [https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)\n",
    "\n",
    "1. [https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "\n",
    "1. [https://www.kaggle.com/startupsci/titanic-data-science-solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions)\n",
    "\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3218340bb7dfc4ab53987820284a5c2b1c34eb45"
   },
   "source": [
    "### The kernel is not complete and will be updated soon  !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
