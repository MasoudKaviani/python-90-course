{
  "cells": [
    {
      "metadata": {
        "_uuid": "726661972b09b03a31d424ef02a9be0cd284d81b"
      },
      "cell_type": "markdown",
      "source": " # <div style=\"text-align: center\">Tutorial on Ensemble Learning (Don't Overfit) </div>\n <img src='https://data-science-blog.com/wp-content/uploads/2017/12/ensemble-learning-stacking.png' width=400 height=400 >\n### <div style=\"text-align: center\"> Quite Practical and Far from any Theoretical Concepts </div>\n<div style=\"text-align:center\">last update: <b>18/02/2019</b></div>\n\n\n>You are reading **10 Steps to Become a Data Scientist** and are now in the 8th step : \n\n1. [Leren Python](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)\n2. [Python Packages](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)\n3. [Mathematics and Linear Algebra](https://www.kaggle.com/mjbahmani/linear-algebra-for-data-scientists)\n4. [Programming &amp; Analysis Tools](https://www.kaggle.com/mjbahmani/20-ml-algorithms-15-plot-for-beginners)\n5. [Big Data](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)\n6. [Data visualization](https://www.kaggle.com/mjbahmani/top-5-data-visualization-libraries-tutorial)\n7. [Data Cleaning](https://www.kaggle.com/mjbahmani/machine-learning-workflow-for-house-prices)\n8. <font color=\"red\">You are in the 8th step</font>\n9. [A Comprehensive ML  Workflow with Python](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)\n10. [Deep Learning](https://www.kaggle.com/mjbahmani/top-5-deep-learning-frameworks-tutorial)\n\n\nyou can Fork and Run this kernel on <font color=\"red\">Github</font>:\n\n> [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\n **I hope you find this kernel helpful and some <font color='red'> UPVOTES</font> would be very much appreciated**\n \n -----------"
    },
    {
      "metadata": {
        "_uuid": "2a01be35950f7a117fc6700e866de3bf5a3ea6b9"
      },
      "cell_type": "markdown",
      "source": "<a id=\"top\"></a> <br>\n## Notebook  Content\n1. [Introduction](#1)\n1. [Import packages](#2)\n    1. [Version](#21)\n    1. [Setup](#22)\n    1. [Data Collection](#23)\n1. [What's Ensemble Learning?](#3)\n    1. [Why Ensemble Learning?](#31)\n1. [Ensemble Techniques](#4)\n    1. [what-is-the-difference-between-bagging-and-boosting?](#41)\n1. [Model Deployment](#5)\n    1. [Prepare Features & Targets](#51)\n    1. [RandomForest](#52)\n    1. [Bagging classifier ](#53)\n    1. [AdaBoost](#54)\n    1. [Gradient Boosting Classifier](#55)\n    1. [Linear Discriminant Analysis](#56)\n    1. [Quadratic Discriminant Analysis](#57)\n1. [Conclusion](#6)\n1. [References & Credits](#7)"
    },
    {
      "metadata": {
        "_uuid": "b18443661b6d30ffea2150fa74d44d62e14ae952"
      },
      "cell_type": "markdown",
      "source": "<a id=\"1\"></a> <br>\n#  1- Introduction\nIn this kernel, I want to start explorer everything about **Ensemble modeling**. I will run plenty of algorithms on various datasets. I hope you enjoy and give me feedback."
    },
    {
      "metadata": {
        "_uuid": "18e6a0730989363caa069a745b5f3ea8b30766e9"
      },
      "cell_type": "markdown",
      "source": "<a id=\"2\"></a> <br>\n## 2- Import packages"
    },
    {
      "metadata": {
        "_uuid": "5b8aa15d1b11789c38f1dd19d5f06e4be054e525",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom pandas import get_dummies\nimport plotly.graph_objs as go\nfrom sklearn import datasets\nimport plotly.plotly as py\nimport seaborn as sns\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\nimport sklearn\nimport scipy\nimport numpy\nimport json\nimport sys\nimport csv\nimport os",
      "execution_count": 112,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c9e3318fd92fab57b39625950c2e805bc83fa06f"
      },
      "cell_type": "markdown",
      "source": "<a id=\"21\"></a> <br>\n### 2-1 Version"
    },
    {
      "metadata": {
        "_uuid": "49d5cacd5d0aeadd10836b930cdb43e0ed581a60",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "print('matplotlib: {}'.format(matplotlib.__version__))\nprint('sklearn: {}'.format(sklearn.__version__))\nprint('scipy: {}'.format(scipy.__version__))\nprint('seaborn: {}'.format(sns.__version__))\nprint('pandas: {}'.format(pd.__version__))\nprint('numpy: {}'.format(np.__version__))\nprint('Python: {}'.format(sys.version))",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": "matplotlib: 2.2.3\nsklearn: 0.20.2\nscipy: 1.1.0\nseaborn: 0.9.0\npandas: 0.23.4\nnumpy: 1.16.0\nPython: 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) \n[GCC 7.3.0]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ef3610612578ce105a0e8d08693b0ca9e75dcb06"
      },
      "cell_type": "markdown",
      "source": "<a id=\"22\"></a> <br>\n### 2-2 Setup\n\nA few tiny adjustments for better **code readability**"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "3fe93eb33b3c1499d10da8d9840e13ac29cb64d5"
      },
      "cell_type": "code",
      "source": "warnings.filterwarnings('ignore')\nsns.set(color_codes=True)\nplt.style.available\n%matplotlib inline\n%precision 2",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 114,
          "data": {
            "text/plain": "'%.2f'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e5c5a1da5ce973e4dce69388b76022b5f69e4c16"
      },
      "cell_type": "markdown",
      "source": "<a id=\"23\"></a> <br>\n### 2-3 Data Collection\nwe have used  Two Sigma  data sets"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "9984b27faa5c86b3e6032264b155278acdabccda"
      },
      "cell_type": "code",
      "source": "import os\nprint([filename for filename in os.listdir('../input') if '.csv' in filename])",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv', 'sample_submission.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1f4c3ec8ecd51cc0ae810666af8f93d6d1d27aaf",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# import Dataset to play with it\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')",
      "execution_count": 116,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2974f6767ce89a2dfd769c55d2c8b9128754c95c"
      },
      "cell_type": "code",
      "source": "sample_submission = pd.read_csv('../input/sample_submission.csv')\nsample_submission.head()",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 117,
          "data": {
            "text/plain": "    id  target\n0  250       0\n1  251       0\n2  252       0\n3  253       0\n4  254       0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>250</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>251</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>252</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>253</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>254</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a6db3370c16c7e91d1d1624bc88a35cde1f8f141"
      },
      "cell_type": "markdown",
      "source": "**<< Note 1 >>**\n\n* Each row is an observation (also known as : sample, example, instance, record)\n* Each column is a feature (also known as: Predictor, attribute, Independent Variable, input, regressor, Covariate)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef1df8591232bc1f17d323075b4a92cb0a349adf"
      },
      "cell_type": "code",
      "source": "train.shape, test.shape, sample_submission.shape",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 118,
          "data": {
            "text/plain": "((250, 302), (19750, 301), (19750, 2))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf202ebdb10fa7b2c6d94c508734a1106366f251"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 119,
          "data": {
            "text/plain": "   id  target      0      1      2  ...      295    296    297    298    299\n0   0     1.0 -0.098  2.165  0.681  ...   -2.097  1.051 -0.414  1.038 -1.065\n1   1     0.0  1.081 -0.973 -0.383  ...   -1.624 -0.458 -1.099 -0.936  0.973\n2   2     1.0 -0.523 -0.089 -0.348  ...   -1.165 -1.544  0.004  0.800 -1.211\n3   3     1.0  0.067 -0.021  0.392  ...    0.467 -0.562 -0.254 -0.533  0.238\n4   4     1.0  2.347 -0.831  0.511  ...    1.378  1.246  1.478  0.428  0.253\n\n[5 rows x 302 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>...</th>\n      <th>260</th>\n      <th>261</th>\n      <th>262</th>\n      <th>263</th>\n      <th>264</th>\n      <th>265</th>\n      <th>266</th>\n      <th>267</th>\n      <th>268</th>\n      <th>269</th>\n      <th>270</th>\n      <th>271</th>\n      <th>272</th>\n      <th>273</th>\n      <th>274</th>\n      <th>275</th>\n      <th>276</th>\n      <th>277</th>\n      <th>278</th>\n      <th>279</th>\n      <th>280</th>\n      <th>281</th>\n      <th>282</th>\n      <th>283</th>\n      <th>284</th>\n      <th>285</th>\n      <th>286</th>\n      <th>287</th>\n      <th>288</th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>-0.098</td>\n      <td>2.165</td>\n      <td>0.681</td>\n      <td>-0.614</td>\n      <td>1.309</td>\n      <td>-0.455</td>\n      <td>-0.236</td>\n      <td>0.276</td>\n      <td>-2.246</td>\n      <td>1.825</td>\n      <td>-0.912</td>\n      <td>-0.107</td>\n      <td>0.305</td>\n      <td>0.102</td>\n      <td>0.826</td>\n      <td>0.417</td>\n      <td>0.177</td>\n      <td>-0.673</td>\n      <td>-0.503</td>\n      <td>1.864</td>\n      <td>0.410</td>\n      <td>-1.927</td>\n      <td>0.102</td>\n      <td>-0.931</td>\n      <td>1.763</td>\n      <td>1.449</td>\n      <td>-1.097</td>\n      <td>-0.686</td>\n      <td>-0.250</td>\n      <td>-1.859</td>\n      <td>1.125</td>\n      <td>1.009</td>\n      <td>-2.296</td>\n      <td>0.385</td>\n      <td>-0.876</td>\n      <td>1.528</td>\n      <td>-0.144</td>\n      <td>-1.078</td>\n      <td>...</td>\n      <td>-0.681</td>\n      <td>1.250</td>\n      <td>-0.565</td>\n      <td>-1.318</td>\n      <td>-0.923</td>\n      <td>0.075</td>\n      <td>-0.704</td>\n      <td>2.457</td>\n      <td>0.771</td>\n      <td>-0.460</td>\n      <td>0.569</td>\n      <td>-1.320</td>\n      <td>-1.516</td>\n      <td>-2.145</td>\n      <td>-1.120</td>\n      <td>0.156</td>\n      <td>0.820</td>\n      <td>-1.049</td>\n      <td>-1.125</td>\n      <td>0.484</td>\n      <td>0.617</td>\n      <td>1.253</td>\n      <td>1.248</td>\n      <td>0.504</td>\n      <td>-0.802</td>\n      <td>-0.896</td>\n      <td>-1.793</td>\n      <td>-0.284</td>\n      <td>-0.601</td>\n      <td>0.569</td>\n      <td>0.867</td>\n      <td>1.347</td>\n      <td>0.504</td>\n      <td>-0.649</td>\n      <td>0.672</td>\n      <td>-2.097</td>\n      <td>1.051</td>\n      <td>-0.414</td>\n      <td>1.038</td>\n      <td>-1.065</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.081</td>\n      <td>-0.973</td>\n      <td>-0.383</td>\n      <td>0.326</td>\n      <td>-0.428</td>\n      <td>0.317</td>\n      <td>1.172</td>\n      <td>0.352</td>\n      <td>0.004</td>\n      <td>-0.291</td>\n      <td>2.907</td>\n      <td>1.085</td>\n      <td>2.144</td>\n      <td>1.540</td>\n      <td>0.584</td>\n      <td>1.133</td>\n      <td>1.098</td>\n      <td>-0.237</td>\n      <td>-0.498</td>\n      <td>0.283</td>\n      <td>-1.100</td>\n      <td>-0.417</td>\n      <td>1.382</td>\n      <td>-0.515</td>\n      <td>-1.519</td>\n      <td>0.619</td>\n      <td>-0.128</td>\n      <td>0.866</td>\n      <td>-0.540</td>\n      <td>1.238</td>\n      <td>-0.227</td>\n      <td>0.269</td>\n      <td>-0.390</td>\n      <td>-2.721</td>\n      <td>1.659</td>\n      <td>0.106</td>\n      <td>-0.121</td>\n      <td>1.719</td>\n      <td>...</td>\n      <td>0.971</td>\n      <td>-1.489</td>\n      <td>0.530</td>\n      <td>0.917</td>\n      <td>-0.094</td>\n      <td>-1.407</td>\n      <td>0.887</td>\n      <td>-0.104</td>\n      <td>-0.583</td>\n      <td>1.267</td>\n      <td>-1.667</td>\n      <td>-2.771</td>\n      <td>-0.516</td>\n      <td>1.312</td>\n      <td>0.491</td>\n      <td>0.932</td>\n      <td>2.064</td>\n      <td>0.422</td>\n      <td>1.215</td>\n      <td>2.012</td>\n      <td>0.043</td>\n      <td>-0.307</td>\n      <td>-0.059</td>\n      <td>1.121</td>\n      <td>1.333</td>\n      <td>0.211</td>\n      <td>1.753</td>\n      <td>0.053</td>\n      <td>1.274</td>\n      <td>-0.612</td>\n      <td>-0.165</td>\n      <td>-1.695</td>\n      <td>-1.257</td>\n      <td>1.359</td>\n      <td>-0.808</td>\n      <td>-1.624</td>\n      <td>-0.458</td>\n      <td>-1.099</td>\n      <td>-0.936</td>\n      <td>0.973</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>-0.523</td>\n      <td>-0.089</td>\n      <td>-0.348</td>\n      <td>0.148</td>\n      <td>-0.022</td>\n      <td>0.404</td>\n      <td>-0.023</td>\n      <td>-0.172</td>\n      <td>0.137</td>\n      <td>0.183</td>\n      <td>0.459</td>\n      <td>0.478</td>\n      <td>-0.425</td>\n      <td>0.352</td>\n      <td>1.095</td>\n      <td>0.300</td>\n      <td>-1.044</td>\n      <td>0.270</td>\n      <td>-1.038</td>\n      <td>0.144</td>\n      <td>-1.658</td>\n      <td>-0.946</td>\n      <td>0.633</td>\n      <td>-0.772</td>\n      <td>1.786</td>\n      <td>0.136</td>\n      <td>-0.103</td>\n      <td>-1.223</td>\n      <td>2.273</td>\n      <td>0.055</td>\n      <td>-2.032</td>\n      <td>-0.452</td>\n      <td>0.064</td>\n      <td>0.924</td>\n      <td>-0.692</td>\n      <td>-0.067</td>\n      <td>-0.917</td>\n      <td>1.896</td>\n      <td>...</td>\n      <td>-0.540</td>\n      <td>-0.299</td>\n      <td>1.074</td>\n      <td>-0.748</td>\n      <td>1.086</td>\n      <td>-0.766</td>\n      <td>-0.931</td>\n      <td>0.432</td>\n      <td>1.345</td>\n      <td>-0.491</td>\n      <td>-1.602</td>\n      <td>-0.727</td>\n      <td>0.346</td>\n      <td>0.780</td>\n      <td>-0.527</td>\n      <td>-1.122</td>\n      <td>-0.208</td>\n      <td>-0.730</td>\n      <td>-0.302</td>\n      <td>2.535</td>\n      <td>-1.045</td>\n      <td>0.037</td>\n      <td>0.020</td>\n      <td>1.373</td>\n      <td>0.456</td>\n      <td>-0.277</td>\n      <td>1.381</td>\n      <td>1.843</td>\n      <td>0.749</td>\n      <td>0.202</td>\n      <td>0.013</td>\n      <td>0.263</td>\n      <td>-1.222</td>\n      <td>0.726</td>\n      <td>1.444</td>\n      <td>-1.165</td>\n      <td>-1.544</td>\n      <td>0.004</td>\n      <td>0.800</td>\n      <td>-1.211</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0.067</td>\n      <td>-0.021</td>\n      <td>0.392</td>\n      <td>-1.637</td>\n      <td>-0.446</td>\n      <td>-0.725</td>\n      <td>-1.035</td>\n      <td>0.834</td>\n      <td>0.503</td>\n      <td>0.274</td>\n      <td>0.335</td>\n      <td>-1.148</td>\n      <td>0.067</td>\n      <td>-1.010</td>\n      <td>1.048</td>\n      <td>-1.442</td>\n      <td>0.210</td>\n      <td>0.836</td>\n      <td>-0.326</td>\n      <td>0.716</td>\n      <td>-0.764</td>\n      <td>0.248</td>\n      <td>-1.308</td>\n      <td>2.127</td>\n      <td>0.365</td>\n      <td>0.296</td>\n      <td>-0.808</td>\n      <td>1.854</td>\n      <td>0.118</td>\n      <td>0.380</td>\n      <td>0.999</td>\n      <td>-1.171</td>\n      <td>2.798</td>\n      <td>0.394</td>\n      <td>-1.048</td>\n      <td>1.078</td>\n      <td>0.401</td>\n      <td>-0.486</td>\n      <td>...</td>\n      <td>-0.083</td>\n      <td>-0.831</td>\n      <td>1.251</td>\n      <td>-0.206</td>\n      <td>-0.933</td>\n      <td>-1.215</td>\n      <td>0.281</td>\n      <td>0.512</td>\n      <td>-0.424</td>\n      <td>0.769</td>\n      <td>0.223</td>\n      <td>-0.710</td>\n      <td>2.725</td>\n      <td>0.176</td>\n      <td>0.845</td>\n      <td>-1.226</td>\n      <td>1.527</td>\n      <td>-1.701</td>\n      <td>0.597</td>\n      <td>0.150</td>\n      <td>1.864</td>\n      <td>0.322</td>\n      <td>-0.214</td>\n      <td>1.282</td>\n      <td>0.408</td>\n      <td>-0.910</td>\n      <td>1.020</td>\n      <td>-0.299</td>\n      <td>-1.574</td>\n      <td>-1.618</td>\n      <td>-0.404</td>\n      <td>0.640</td>\n      <td>-0.595</td>\n      <td>-0.966</td>\n      <td>0.900</td>\n      <td>0.467</td>\n      <td>-0.562</td>\n      <td>-0.254</td>\n      <td>-0.533</td>\n      <td>0.238</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2.347</td>\n      <td>-0.831</td>\n      <td>0.511</td>\n      <td>-0.021</td>\n      <td>1.225</td>\n      <td>1.594</td>\n      <td>0.585</td>\n      <td>1.509</td>\n      <td>-0.012</td>\n      <td>2.198</td>\n      <td>0.190</td>\n      <td>0.453</td>\n      <td>0.494</td>\n      <td>1.478</td>\n      <td>-1.412</td>\n      <td>0.270</td>\n      <td>-1.312</td>\n      <td>-0.322</td>\n      <td>-0.688</td>\n      <td>-0.198</td>\n      <td>-0.285</td>\n      <td>1.042</td>\n      <td>-0.315</td>\n      <td>-0.478</td>\n      <td>0.024</td>\n      <td>-0.190</td>\n      <td>1.656</td>\n      <td>-0.469</td>\n      <td>-1.437</td>\n      <td>-0.581</td>\n      <td>-0.308</td>\n      <td>-0.837</td>\n      <td>-1.739</td>\n      <td>0.037</td>\n      <td>0.336</td>\n      <td>-1.102</td>\n      <td>2.371</td>\n      <td>0.554</td>\n      <td>...</td>\n      <td>-1.050</td>\n      <td>-0.347</td>\n      <td>0.904</td>\n      <td>-1.324</td>\n      <td>-0.849</td>\n      <td>3.432</td>\n      <td>0.222</td>\n      <td>0.416</td>\n      <td>0.174</td>\n      <td>-1.517</td>\n      <td>-0.337</td>\n      <td>0.055</td>\n      <td>-0.464</td>\n      <td>0.014</td>\n      <td>-1.073</td>\n      <td>0.325</td>\n      <td>-0.523</td>\n      <td>-0.692</td>\n      <td>0.190</td>\n      <td>-0.883</td>\n      <td>-1.830</td>\n      <td>1.408</td>\n      <td>2.319</td>\n      <td>1.704</td>\n      <td>-0.723</td>\n      <td>1.014</td>\n      <td>0.064</td>\n      <td>0.096</td>\n      <td>-0.775</td>\n      <td>1.845</td>\n      <td>0.898</td>\n      <td>0.134</td>\n      <td>2.415</td>\n      <td>-0.996</td>\n      <td>-1.006</td>\n      <td>1.378</td>\n      <td>1.246</td>\n      <td>1.478</td>\n      <td>0.428</td>\n      <td>0.253</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f6e45279b5889ee78cc670ec16ec9d7561d2ece"
      },
      "cell_type": "code",
      "source": "test.head()",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 120,
          "data": {
            "text/plain": "    id      0      1      2      3  ...      295    296    297    298    299\n0  250  0.500 -1.033 -1.595  0.309  ...    2.132  0.609 -0.104  0.312  0.979\n1  251  0.776  0.914 -0.494  1.347  ...   -1.133 -3.138  0.281 -0.625 -0.761\n2  252  1.750  0.509 -0.057  0.835  ...    0.701  0.976  0.135 -1.327  2.463\n3  253 -0.556 -1.855 -0.682  0.578  ...    0.916  2.411  1.053 -1.601 -1.529\n4  254  0.754 -0.245  1.173 -1.623  ...    0.322 -0.068 -0.156 -1.153  0.825\n\n[5 rows x 301 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>...</th>\n      <th>260</th>\n      <th>261</th>\n      <th>262</th>\n      <th>263</th>\n      <th>264</th>\n      <th>265</th>\n      <th>266</th>\n      <th>267</th>\n      <th>268</th>\n      <th>269</th>\n      <th>270</th>\n      <th>271</th>\n      <th>272</th>\n      <th>273</th>\n      <th>274</th>\n      <th>275</th>\n      <th>276</th>\n      <th>277</th>\n      <th>278</th>\n      <th>279</th>\n      <th>280</th>\n      <th>281</th>\n      <th>282</th>\n      <th>283</th>\n      <th>284</th>\n      <th>285</th>\n      <th>286</th>\n      <th>287</th>\n      <th>288</th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>250</td>\n      <td>0.500</td>\n      <td>-1.033</td>\n      <td>-1.595</td>\n      <td>0.309</td>\n      <td>-0.714</td>\n      <td>0.502</td>\n      <td>0.535</td>\n      <td>-0.129</td>\n      <td>-0.687</td>\n      <td>1.291</td>\n      <td>0.507</td>\n      <td>-0.317</td>\n      <td>1.848</td>\n      <td>-0.232</td>\n      <td>-0.340</td>\n      <td>-0.051</td>\n      <td>0.804</td>\n      <td>0.764</td>\n      <td>1.860</td>\n      <td>0.262</td>\n      <td>1.112</td>\n      <td>-0.491</td>\n      <td>-1.039</td>\n      <td>-0.492</td>\n      <td>0.183</td>\n      <td>-0.671</td>\n      <td>-1.313</td>\n      <td>0.149</td>\n      <td>0.244</td>\n      <td>1.072</td>\n      <td>-1.003</td>\n      <td>0.832</td>\n      <td>-1.075</td>\n      <td>1.988</td>\n      <td>1.201</td>\n      <td>-2.065</td>\n      <td>-0.826</td>\n      <td>-0.016</td>\n      <td>0.490</td>\n      <td>...</td>\n      <td>0.824</td>\n      <td>0.928</td>\n      <td>1.372</td>\n      <td>1.505</td>\n      <td>0.645</td>\n      <td>0.641</td>\n      <td>-1.132</td>\n      <td>1.009</td>\n      <td>0.998</td>\n      <td>0.210</td>\n      <td>-1.634</td>\n      <td>1.046</td>\n      <td>0.114</td>\n      <td>-0.806</td>\n      <td>0.301</td>\n      <td>0.145</td>\n      <td>-0.684</td>\n      <td>0.794</td>\n      <td>-0.290</td>\n      <td>-1.688</td>\n      <td>0.313</td>\n      <td>1.140</td>\n      <td>0.447</td>\n      <td>-0.616</td>\n      <td>1.294</td>\n      <td>0.785</td>\n      <td>0.453</td>\n      <td>1.550</td>\n      <td>-0.866</td>\n      <td>1.007</td>\n      <td>-0.088</td>\n      <td>-2.628</td>\n      <td>-0.845</td>\n      <td>2.078</td>\n      <td>-0.277</td>\n      <td>2.132</td>\n      <td>0.609</td>\n      <td>-0.104</td>\n      <td>0.312</td>\n      <td>0.979</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>251</td>\n      <td>0.776</td>\n      <td>0.914</td>\n      <td>-0.494</td>\n      <td>1.347</td>\n      <td>-0.867</td>\n      <td>0.480</td>\n      <td>0.578</td>\n      <td>-0.313</td>\n      <td>0.203</td>\n      <td>1.356</td>\n      <td>-1.086</td>\n      <td>0.322</td>\n      <td>0.876</td>\n      <td>-0.563</td>\n      <td>-1.394</td>\n      <td>0.385</td>\n      <td>1.891</td>\n      <td>-2.107</td>\n      <td>-0.636</td>\n      <td>-0.055</td>\n      <td>-0.843</td>\n      <td>0.041</td>\n      <td>0.253</td>\n      <td>0.557</td>\n      <td>0.475</td>\n      <td>-0.839</td>\n      <td>-1.146</td>\n      <td>1.210</td>\n      <td>1.427</td>\n      <td>0.347</td>\n      <td>1.077</td>\n      <td>-0.194</td>\n      <td>0.323</td>\n      <td>0.543</td>\n      <td>0.894</td>\n      <td>1.190</td>\n      <td>0.342</td>\n      <td>-0.858</td>\n      <td>0.756</td>\n      <td>...</td>\n      <td>-1.791</td>\n      <td>0.122</td>\n      <td>-0.669</td>\n      <td>-1.558</td>\n      <td>-0.244</td>\n      <td>2.583</td>\n      <td>-0.829</td>\n      <td>0.133</td>\n      <td>-2.746</td>\n      <td>0.341</td>\n      <td>-1.145</td>\n      <td>0.492</td>\n      <td>0.437</td>\n      <td>-0.628</td>\n      <td>0.271</td>\n      <td>2.639</td>\n      <td>0.481</td>\n      <td>-0.687</td>\n      <td>1.017</td>\n      <td>1.648</td>\n      <td>-1.272</td>\n      <td>-0.797</td>\n      <td>-0.870</td>\n      <td>-1.582</td>\n      <td>-1.987</td>\n      <td>-0.052</td>\n      <td>-0.194</td>\n      <td>0.539</td>\n      <td>-1.788</td>\n      <td>-0.433</td>\n      <td>-0.683</td>\n      <td>-0.066</td>\n      <td>0.025</td>\n      <td>0.606</td>\n      <td>-0.353</td>\n      <td>-1.133</td>\n      <td>-3.138</td>\n      <td>0.281</td>\n      <td>-0.625</td>\n      <td>-0.761</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>252</td>\n      <td>1.750</td>\n      <td>0.509</td>\n      <td>-0.057</td>\n      <td>0.835</td>\n      <td>-0.476</td>\n      <td>1.428</td>\n      <td>-0.701</td>\n      <td>-2.009</td>\n      <td>-1.378</td>\n      <td>0.167</td>\n      <td>-0.132</td>\n      <td>0.459</td>\n      <td>-0.341</td>\n      <td>0.014</td>\n      <td>0.184</td>\n      <td>-0.460</td>\n      <td>-0.991</td>\n      <td>-1.039</td>\n      <td>0.992</td>\n      <td>1.036</td>\n      <td>1.552</td>\n      <td>-0.830</td>\n      <td>1.374</td>\n      <td>-0.914</td>\n      <td>0.427</td>\n      <td>0.027</td>\n      <td>0.327</td>\n      <td>1.117</td>\n      <td>0.871</td>\n      <td>-2.556</td>\n      <td>-0.036</td>\n      <td>-0.081</td>\n      <td>0.744</td>\n      <td>-1.191</td>\n      <td>-1.784</td>\n      <td>0.239</td>\n      <td>0.500</td>\n      <td>0.437</td>\n      <td>0.746</td>\n      <td>...</td>\n      <td>-1.167</td>\n      <td>1.009</td>\n      <td>-0.180</td>\n      <td>-0.683</td>\n      <td>-1.383</td>\n      <td>1.020</td>\n      <td>0.268</td>\n      <td>-1.558</td>\n      <td>0.620</td>\n      <td>-0.489</td>\n      <td>-2.090</td>\n      <td>-0.977</td>\n      <td>1.672</td>\n      <td>-0.655</td>\n      <td>-0.801</td>\n      <td>-1.846</td>\n      <td>0.761</td>\n      <td>-0.846</td>\n      <td>0.181</td>\n      <td>0.962</td>\n      <td>-0.611</td>\n      <td>1.450</td>\n      <td>0.021</td>\n      <td>0.320</td>\n      <td>-0.951</td>\n      <td>-2.662</td>\n      <td>0.761</td>\n      <td>-0.665</td>\n      <td>-0.619</td>\n      <td>-0.645</td>\n      <td>-0.094</td>\n      <td>0.351</td>\n      <td>-0.607</td>\n      <td>-0.737</td>\n      <td>-0.031</td>\n      <td>0.701</td>\n      <td>0.976</td>\n      <td>0.135</td>\n      <td>-1.327</td>\n      <td>2.463</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>253</td>\n      <td>-0.556</td>\n      <td>-1.855</td>\n      <td>-0.682</td>\n      <td>0.578</td>\n      <td>1.592</td>\n      <td>0.512</td>\n      <td>-1.419</td>\n      <td>0.722</td>\n      <td>0.511</td>\n      <td>0.567</td>\n      <td>0.356</td>\n      <td>-0.060</td>\n      <td>0.767</td>\n      <td>-0.196</td>\n      <td>0.359</td>\n      <td>0.080</td>\n      <td>-0.956</td>\n      <td>0.857</td>\n      <td>-0.655</td>\n      <td>-0.090</td>\n      <td>-0.008</td>\n      <td>-0.596</td>\n      <td>-0.413</td>\n      <td>-1.030</td>\n      <td>0.173</td>\n      <td>-0.969</td>\n      <td>0.998</td>\n      <td>0.079</td>\n      <td>0.790</td>\n      <td>-0.776</td>\n      <td>-0.374</td>\n      <td>-1.995</td>\n      <td>0.572</td>\n      <td>0.542</td>\n      <td>0.547</td>\n      <td>0.307</td>\n      <td>-0.074</td>\n      <td>1.703</td>\n      <td>-0.003</td>\n      <td>...</td>\n      <td>-1.029</td>\n      <td>-0.340</td>\n      <td>0.052</td>\n      <td>2.122</td>\n      <td>-0.136</td>\n      <td>-1.799</td>\n      <td>1.450</td>\n      <td>1.866</td>\n      <td>-0.273</td>\n      <td>-0.237</td>\n      <td>-0.207</td>\n      <td>-0.196</td>\n      <td>-1.106</td>\n      <td>-1.560</td>\n      <td>-0.934</td>\n      <td>2.167</td>\n      <td>0.323</td>\n      <td>0.583</td>\n      <td>1.480</td>\n      <td>-0.685</td>\n      <td>-0.473</td>\n      <td>-1.066</td>\n      <td>-0.271</td>\n      <td>0.506</td>\n      <td>-0.753</td>\n      <td>1.048</td>\n      <td>-0.450</td>\n      <td>-0.300</td>\n      <td>-1.221</td>\n      <td>0.235</td>\n      <td>-0.336</td>\n      <td>-0.787</td>\n      <td>0.255</td>\n      <td>-0.031</td>\n      <td>-0.836</td>\n      <td>0.916</td>\n      <td>2.411</td>\n      <td>1.053</td>\n      <td>-1.601</td>\n      <td>-1.529</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>254</td>\n      <td>0.754</td>\n      <td>-0.245</td>\n      <td>1.173</td>\n      <td>-1.623</td>\n      <td>0.009</td>\n      <td>0.370</td>\n      <td>0.781</td>\n      <td>-1.763</td>\n      <td>-1.432</td>\n      <td>-0.930</td>\n      <td>-0.098</td>\n      <td>0.896</td>\n      <td>0.293</td>\n      <td>-0.259</td>\n      <td>0.030</td>\n      <td>-0.661</td>\n      <td>0.921</td>\n      <td>0.006</td>\n      <td>-0.631</td>\n      <td>1.284</td>\n      <td>-1.167</td>\n      <td>-0.744</td>\n      <td>-2.184</td>\n      <td>2.146</td>\n      <td>1.130</td>\n      <td>0.017</td>\n      <td>1.421</td>\n      <td>-0.590</td>\n      <td>1.938</td>\n      <td>-0.194</td>\n      <td>0.794</td>\n      <td>0.579</td>\n      <td>0.521</td>\n      <td>0.635</td>\n      <td>-0.023</td>\n      <td>-0.892</td>\n      <td>-0.363</td>\n      <td>-0.360</td>\n      <td>0.405</td>\n      <td>...</td>\n      <td>-0.486</td>\n      <td>-0.068</td>\n      <td>-0.534</td>\n      <td>-1.322</td>\n      <td>0.500</td>\n      <td>0.263</td>\n      <td>-0.745</td>\n      <td>0.578</td>\n      <td>-0.064</td>\n      <td>0.738</td>\n      <td>-0.280</td>\n      <td>0.745</td>\n      <td>-0.588</td>\n      <td>-0.429</td>\n      <td>-0.588</td>\n      <td>0.154</td>\n      <td>-1.187</td>\n      <td>1.681</td>\n      <td>-0.832</td>\n      <td>-0.437</td>\n      <td>-0.038</td>\n      <td>-1.096</td>\n      <td>-0.156</td>\n      <td>3.565</td>\n      <td>-0.428</td>\n      <td>-0.384</td>\n      <td>1.243</td>\n      <td>-0.966</td>\n      <td>1.525</td>\n      <td>0.458</td>\n      <td>2.184</td>\n      <td>-1.090</td>\n      <td>0.216</td>\n      <td>1.186</td>\n      <td>-0.143</td>\n      <td>0.322</td>\n      <td>-0.068</td>\n      <td>-0.156</td>\n      <td>-1.153</td>\n      <td>0.825</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c16f2b1e79336a2040cee5493ac260297be04b3"
      },
      "cell_type": "code",
      "source": "train.tail()",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 121,
          "data": {
            "text/plain": "      id  target      0      1      2  ...      295    296    297    298    299\n245  245     0.0 -1.199  0.466 -0.908  ...   -0.243  0.525  0.281 -0.255 -1.136\n246  246     0.0  0.237  0.233 -0.380  ...    1.004 -0.979  0.007  0.112 -0.558\n247  247     0.0  1.411 -1.465  0.119  ...   -0.727  0.461  0.760  0.168 -0.719\n248  248     1.0  0.620  1.040  0.184  ...    0.478 -0.910 -0.805  2.029 -0.423\n249  249     0.0  0.489  0.403  0.139  ...    0.812  0.269 -1.454 -0.625  1.474\n\n[5 rows x 302 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>...</th>\n      <th>260</th>\n      <th>261</th>\n      <th>262</th>\n      <th>263</th>\n      <th>264</th>\n      <th>265</th>\n      <th>266</th>\n      <th>267</th>\n      <th>268</th>\n      <th>269</th>\n      <th>270</th>\n      <th>271</th>\n      <th>272</th>\n      <th>273</th>\n      <th>274</th>\n      <th>275</th>\n      <th>276</th>\n      <th>277</th>\n      <th>278</th>\n      <th>279</th>\n      <th>280</th>\n      <th>281</th>\n      <th>282</th>\n      <th>283</th>\n      <th>284</th>\n      <th>285</th>\n      <th>286</th>\n      <th>287</th>\n      <th>288</th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>245</th>\n      <td>245</td>\n      <td>0.0</td>\n      <td>-1.199</td>\n      <td>0.466</td>\n      <td>-0.908</td>\n      <td>2.771</td>\n      <td>1.631</td>\n      <td>0.931</td>\n      <td>0.182</td>\n      <td>-0.652</td>\n      <td>-0.512</td>\n      <td>0.400</td>\n      <td>1.608</td>\n      <td>0.937</td>\n      <td>1.663</td>\n      <td>0.696</td>\n      <td>-1.874</td>\n      <td>1.044</td>\n      <td>0.851</td>\n      <td>-1.070</td>\n      <td>-0.095</td>\n      <td>-1.386</td>\n      <td>-0.219</td>\n      <td>0.101</td>\n      <td>0.250</td>\n      <td>-0.465</td>\n      <td>-0.455</td>\n      <td>0.538</td>\n      <td>2.581</td>\n      <td>-1.612</td>\n      <td>1.166</td>\n      <td>1.682</td>\n      <td>-1.574</td>\n      <td>-0.304</td>\n      <td>0.355</td>\n      <td>-1.416</td>\n      <td>-0.823</td>\n      <td>0.359</td>\n      <td>-0.463</td>\n      <td>-1.869</td>\n      <td>...</td>\n      <td>1.588</td>\n      <td>-1.167</td>\n      <td>1.500</td>\n      <td>-1.643</td>\n      <td>-1.944</td>\n      <td>-1.121</td>\n      <td>1.055</td>\n      <td>1.794</td>\n      <td>0.986</td>\n      <td>-1.461</td>\n      <td>0.329</td>\n      <td>1.903</td>\n      <td>0.468</td>\n      <td>-1.826</td>\n      <td>-2.128</td>\n      <td>1.644</td>\n      <td>-0.598</td>\n      <td>0.176</td>\n      <td>-0.517</td>\n      <td>-1.146</td>\n      <td>1.911</td>\n      <td>-0.814</td>\n      <td>-0.073</td>\n      <td>0.155</td>\n      <td>0.323</td>\n      <td>1.060</td>\n      <td>0.324</td>\n      <td>0.460</td>\n      <td>2.213</td>\n      <td>-2.360</td>\n      <td>0.724</td>\n      <td>0.177</td>\n      <td>-0.039</td>\n      <td>0.759</td>\n      <td>0.461</td>\n      <td>-0.243</td>\n      <td>0.525</td>\n      <td>0.281</td>\n      <td>-0.255</td>\n      <td>-1.136</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>246</td>\n      <td>0.0</td>\n      <td>0.237</td>\n      <td>0.233</td>\n      <td>-0.380</td>\n      <td>-1.748</td>\n      <td>0.839</td>\n      <td>-0.721</td>\n      <td>-0.114</td>\n      <td>0.005</td>\n      <td>-1.788</td>\n      <td>1.416</td>\n      <td>-0.683</td>\n      <td>1.079</td>\n      <td>0.195</td>\n      <td>1.879</td>\n      <td>-0.025</td>\n      <td>-0.138</td>\n      <td>-0.276</td>\n      <td>-0.318</td>\n      <td>-0.485</td>\n      <td>0.408</td>\n      <td>-0.261</td>\n      <td>-0.536</td>\n      <td>0.276</td>\n      <td>0.568</td>\n      <td>-0.757</td>\n      <td>-0.915</td>\n      <td>0.989</td>\n      <td>-0.781</td>\n      <td>0.982</td>\n      <td>1.308</td>\n      <td>0.299</td>\n      <td>1.743</td>\n      <td>0.868</td>\n      <td>0.001</td>\n      <td>-0.261</td>\n      <td>-0.620</td>\n      <td>0.459</td>\n      <td>0.116</td>\n      <td>...</td>\n      <td>0.358</td>\n      <td>-0.302</td>\n      <td>-1.353</td>\n      <td>-1.546</td>\n      <td>-1.831</td>\n      <td>0.299</td>\n      <td>1.112</td>\n      <td>1.833</td>\n      <td>-0.420</td>\n      <td>-1.135</td>\n      <td>0.168</td>\n      <td>-0.794</td>\n      <td>-1.598</td>\n      <td>-1.133</td>\n      <td>-0.083</td>\n      <td>1.035</td>\n      <td>0.921</td>\n      <td>-1.279</td>\n      <td>1.123</td>\n      <td>-0.687</td>\n      <td>-0.243</td>\n      <td>1.435</td>\n      <td>-0.036</td>\n      <td>0.103</td>\n      <td>2.155</td>\n      <td>-0.806</td>\n      <td>-0.042</td>\n      <td>0.941</td>\n      <td>-1.469</td>\n      <td>0.457</td>\n      <td>0.857</td>\n      <td>0.147</td>\n      <td>0.601</td>\n      <td>-0.210</td>\n      <td>-0.768</td>\n      <td>1.004</td>\n      <td>-0.979</td>\n      <td>0.007</td>\n      <td>0.112</td>\n      <td>-0.558</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>247</td>\n      <td>0.0</td>\n      <td>1.411</td>\n      <td>-1.465</td>\n      <td>0.119</td>\n      <td>0.583</td>\n      <td>1.634</td>\n      <td>-0.207</td>\n      <td>1.173</td>\n      <td>1.622</td>\n      <td>-0.071</td>\n      <td>-0.695</td>\n      <td>-0.477</td>\n      <td>-1.582</td>\n      <td>-0.521</td>\n      <td>0.389</td>\n      <td>-1.137</td>\n      <td>0.395</td>\n      <td>0.032</td>\n      <td>0.152</td>\n      <td>-1.436</td>\n      <td>-0.799</td>\n      <td>-1.193</td>\n      <td>-0.196</td>\n      <td>-2.888</td>\n      <td>0.922</td>\n      <td>-1.011</td>\n      <td>1.041</td>\n      <td>-0.358</td>\n      <td>-0.642</td>\n      <td>1.241</td>\n      <td>1.615</td>\n      <td>1.995</td>\n      <td>0.301</td>\n      <td>-1.663</td>\n      <td>-0.024</td>\n      <td>-1.448</td>\n      <td>0.538</td>\n      <td>-0.725</td>\n      <td>-0.026</td>\n      <td>...</td>\n      <td>-1.142</td>\n      <td>0.248</td>\n      <td>1.507</td>\n      <td>0.189</td>\n      <td>-0.082</td>\n      <td>-1.621</td>\n      <td>0.906</td>\n      <td>-0.821</td>\n      <td>-0.611</td>\n      <td>0.851</td>\n      <td>0.095</td>\n      <td>-0.305</td>\n      <td>1.074</td>\n      <td>-1.352</td>\n      <td>0.937</td>\n      <td>-2.915</td>\n      <td>0.237</td>\n      <td>0.044</td>\n      <td>-1.755</td>\n      <td>-0.213</td>\n      <td>0.215</td>\n      <td>-1.978</td>\n      <td>1.075</td>\n      <td>1.832</td>\n      <td>-1.504</td>\n      <td>-0.181</td>\n      <td>1.460</td>\n      <td>-0.630</td>\n      <td>1.456</td>\n      <td>0.339</td>\n      <td>-0.499</td>\n      <td>-0.455</td>\n      <td>0.759</td>\n      <td>0.222</td>\n      <td>0.105</td>\n      <td>-0.727</td>\n      <td>0.461</td>\n      <td>0.760</td>\n      <td>0.168</td>\n      <td>-0.719</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>248</td>\n      <td>1.0</td>\n      <td>0.620</td>\n      <td>1.040</td>\n      <td>0.184</td>\n      <td>-0.570</td>\n      <td>-0.087</td>\n      <td>-0.748</td>\n      <td>-1.559</td>\n      <td>-0.553</td>\n      <td>0.552</td>\n      <td>1.284</td>\n      <td>0.944</td>\n      <td>0.306</td>\n      <td>1.222</td>\n      <td>-1.280</td>\n      <td>0.962</td>\n      <td>0.685</td>\n      <td>-1.320</td>\n      <td>-0.359</td>\n      <td>0.614</td>\n      <td>2.486</td>\n      <td>0.438</td>\n      <td>-1.147</td>\n      <td>0.179</td>\n      <td>-1.005</td>\n      <td>-0.798</td>\n      <td>-0.296</td>\n      <td>-0.077</td>\n      <td>-0.755</td>\n      <td>0.046</td>\n      <td>-0.709</td>\n      <td>1.027</td>\n      <td>-0.264</td>\n      <td>-1.324</td>\n      <td>-0.630</td>\n      <td>0.527</td>\n      <td>1.153</td>\n      <td>-1.388</td>\n      <td>-0.172</td>\n      <td>...</td>\n      <td>0.331</td>\n      <td>-1.262</td>\n      <td>-0.262</td>\n      <td>0.661</td>\n      <td>1.289</td>\n      <td>-1.794</td>\n      <td>-0.703</td>\n      <td>-0.666</td>\n      <td>-0.472</td>\n      <td>-1.098</td>\n      <td>1.838</td>\n      <td>-0.186</td>\n      <td>-0.480</td>\n      <td>-1.476</td>\n      <td>0.742</td>\n      <td>-0.481</td>\n      <td>-0.429</td>\n      <td>-1.270</td>\n      <td>1.448</td>\n      <td>-0.204</td>\n      <td>0.465</td>\n      <td>0.980</td>\n      <td>1.941</td>\n      <td>0.656</td>\n      <td>2.384</td>\n      <td>-1.480</td>\n      <td>-0.239</td>\n      <td>1.129</td>\n      <td>2.548</td>\n      <td>-0.120</td>\n      <td>0.557</td>\n      <td>-1.494</td>\n      <td>0.977</td>\n      <td>0.882</td>\n      <td>-1.512</td>\n      <td>0.478</td>\n      <td>-0.910</td>\n      <td>-0.805</td>\n      <td>2.029</td>\n      <td>-0.423</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>249</td>\n      <td>0.0</td>\n      <td>0.489</td>\n      <td>0.403</td>\n      <td>0.139</td>\n      <td>-2.046</td>\n      <td>1.345</td>\n      <td>0.122</td>\n      <td>1.255</td>\n      <td>0.647</td>\n      <td>-0.107</td>\n      <td>0.915</td>\n      <td>-1.514</td>\n      <td>-0.924</td>\n      <td>0.680</td>\n      <td>0.598</td>\n      <td>0.290</td>\n      <td>-0.130</td>\n      <td>0.083</td>\n      <td>-1.633</td>\n      <td>-0.686</td>\n      <td>-0.493</td>\n      <td>-1.127</td>\n      <td>-0.174</td>\n      <td>0.714</td>\n      <td>-0.130</td>\n      <td>1.518</td>\n      <td>0.718</td>\n      <td>1.351</td>\n      <td>-0.877</td>\n      <td>-0.625</td>\n      <td>1.430</td>\n      <td>-0.136</td>\n      <td>-0.468</td>\n      <td>-0.748</td>\n      <td>-0.600</td>\n      <td>0.434</td>\n      <td>-0.955</td>\n      <td>-1.558</td>\n      <td>1.683</td>\n      <td>...</td>\n      <td>-0.682</td>\n      <td>0.847</td>\n      <td>0.140</td>\n      <td>0.174</td>\n      <td>-0.584</td>\n      <td>-1.810</td>\n      <td>0.674</td>\n      <td>0.411</td>\n      <td>0.238</td>\n      <td>-0.032</td>\n      <td>0.496</td>\n      <td>-0.294</td>\n      <td>-1.313</td>\n      <td>-1.510</td>\n      <td>0.458</td>\n      <td>0.356</td>\n      <td>0.615</td>\n      <td>0.066</td>\n      <td>0.328</td>\n      <td>-0.007</td>\n      <td>-1.229</td>\n      <td>0.548</td>\n      <td>0.705</td>\n      <td>-0.147</td>\n      <td>-0.592</td>\n      <td>0.082</td>\n      <td>-0.453</td>\n      <td>0.440</td>\n      <td>-0.434</td>\n      <td>0.216</td>\n      <td>-0.025</td>\n      <td>1.305</td>\n      <td>-1.169</td>\n      <td>1.413</td>\n      <td>0.517</td>\n      <td>0.812</td>\n      <td>0.269</td>\n      <td>-1.454</td>\n      <td>-0.625</td>\n      <td>1.474</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "16ed3be8589772ecfa7eb0e532cdad2257535a96"
      },
      "cell_type": "code",
      "source": "train.columns",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 122,
          "data": {
            "text/plain": "Index(['id', 'target', '0', '1', '2', '3', '4', '5', '6', '7',\n       ...\n       '290', '291', '292', '293', '294', '295', '296', '297', '298', '299'],\n      dtype='object', length=302)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2cc543026b14f18b0d993066df78b58966335ebc"
      },
      "cell_type": "code",
      "source": "print(train.info())",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 250 entries, 0 to 249\nColumns: 302 entries, id to 299\ndtypes: float64(301), int64(1)\nmemory usage: 589.9 KB\nNone\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "2488db5250897fc09954c350d5901f3e90c7f855"
      },
      "cell_type": "markdown",
      "source": "<a id=\"3\"></a> <br>\n## 3- What's Ensemble Learning?\nlet us, review some defination on Ensemble Learning:\n\n1. **Ensemble learning** is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem[9]\n1. **Ensemble Learning** is a powerful way to improve the performance of your model. It usually pays off to apply ensemble learning over and above various models you might be building. Time and again, people have used ensemble models in competitions like Kaggle and benefited from it.[6]\n1. **Ensemble methods** are techniques that create multiple models and then combine them to produce improved results. Ensemble methods usually produces more accurate solutions than a single model would.[10]\n<img src='https://hub.packtpub.com/wp-content/uploads/2018/02/ensemble_machine_learning_image_1-600x407.png'  width=400 height=400>\n[img-ref](https://hub.packtpub.com/wp-content/uploads/2018/02/ensemble_machine_learning_image_1-600x407.png)\n\n> <font color=\"red\"><b>Note</b></font>\nEnsemble Learning is a Machine Learning concept in which the idea is to train multiple models using the same learning algorithm. The ensembles take part in a bigger group of methods, called multiclassifiers, where a set of hundreds or thousands of learners with a common objective are fused together to solve the problem.[11]\n\n> <font color=\"red\"><b>Note</b></font>\nThis Kernel assumes a basic understanding of Machine Learning algorithms. I would recommend going through this [**kernel**](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)  to familiarize yourself with these concepts.\n\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "7ff16eb2e58c508070cd0ab13a3f49ee61456d62"
      },
      "cell_type": "markdown",
      "source": "<a id=\"31\"></a> <br>\n## 3-1 Why Ensemble Learning?\n1. Difference in population\n1. Difference in hypothesis\n1. Difference in modeling technique\n1. Difference in initial seed\n<br>\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "aec8b19e1f21c3133c0b6654c8e219620bce2f60"
      },
      "cell_type": "markdown",
      "source": "<a id=\"4\"></a> <br>\n# 4- Ensemble Techniques\nThe goal of any machine learning problem is to find a single model that will best predict our wanted outcome. Rather than making one model and hoping this model is the best/most accurate predictor we can make, ensemble methods take a myriad of models into account, and average those models to produce one final model.[12]\n<img src='https://uploads.toptal.io/blog/image/92062/toptal-blog-image-1454584029018-cffb1b601292e8d328556e355ed4f7e0.jpg' width=300 height=300>\n[img-ref](https://www.toptal.com/machine-learning/ensemble-methods-machine-learning)\n1. Voting\n1. Weighted Average \n1. Stacking\n1. Blending\n1. Bagging  \n1. Boosting "
    },
    {
      "metadata": {
        "_uuid": "b7523c62ce012e9abba85f7f14cc49f0e0d11bcf"
      },
      "cell_type": "markdown",
      "source": "<a id=\"41\"></a> <br>\n## 4-1 What is the difference between bagging and boosting?\n1. **Bagging**: It is the method to decrease the variance of model by generating additional data for training from your original data set using combinations with repetitions to produce multisets of the same size as your original data.\n    1. Bagging meta-estimator\n    1. Random forest\n1. **Boosting**: It helps to calculate the predict the target variables using different models and then average the result( may be using a weighted average approach).\n    1. AdaBoost\n    1. GBM\n    1. XGBM\n    1. Light GBM\n    1. CatBoost\n    \n<img src='https://www.globalsoftwaresupport.com/wp-content/uploads/2018/02/ds33ggg.png'>\n[img-ref](https://www.globalsoftwaresupport.com/boosting-adaboost-in-machine-learning/)\n<br>\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "72cc7c7b60a33390a85b16bc34e3b9e424650cdd"
      },
      "cell_type": "markdown",
      "source": "<a id=\"5\"></a> <br>\n## 5- Some Ensemble  Model\nIn this section have been applied more than **5 learning algorithms** that play an important rule in your experiences and improve your knowledge in case of ML technique.\n\n> **<< Note 3 >>** : The results shown here may be slightly different for your analysis because, for example, the neural network algorithms use random number generators for fixing the initial value of the weights (starting points) of the neural networks, which often result in obtaining slightly different (local minima) solutions each time you run the analysis. Also note that changing the seed for the random number generator used to create the train, test, and validation samples can change your results.\n<br>\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "daf9910caba26e071ff560dbdaca079ee148e140"
      },
      "cell_type": "markdown",
      "source": "<a id=\"51\"></a> <br>\n## 5-1 Prepare Features & Targets\nFirst of all seperating the data into dependent(Feature) and independent(Target) variables.\n\n**<< Note 4 >>**\n* X==>>Feature\n* y==>>Target"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2b762b5417a8b66b0b5a6dab759da74da242356"
      },
      "cell_type": "code",
      "source": "train['target'].value_counts()",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 124,
          "data": {
            "text/plain": "1.0    160\n0.0     90\nName: target, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b06cb1191a0f52a904c52a918d1f999536e79bda",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "cols=[\"target\",\"id\"]\nX = train.drop(cols,axis=1)\ny = train[\"target\"]",
      "execution_count": 125,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db24cb26b25aa91b46e187753d58b3adecae790c"
      },
      "cell_type": "code",
      "source": "X_test  = test.drop(\"id\",axis=1)",
      "execution_count": 126,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c5fb6c9737fe42a38f03a3733e7775e96015847"
      },
      "cell_type": "code",
      "source": "# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)",
      "execution_count": 127,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "be230bb37d65624a2be449771bd222620a54f99e"
      },
      "cell_type": "markdown",
      "source": "After loading the data via **pandas**, we should checkout what the content is, description and via the following:\n<br>\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "ffc339dbf9c8da74194b994930694bd97bb2afbb"
      },
      "cell_type": "markdown",
      "source": "<a id=\"52\"></a> <br>\n## 5-2 RandomForest\nA random forest is a meta estimator that **fits a number of decision tree classifiers** on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n\nThe sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default)."
    },
    {
      "metadata": {
        "_uuid": "8ed2305b51c2248a8aa62cf4452632f448e83771",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nModel=RandomForestClassifier(max_depth=2)\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_val)\nprint(classification_report(y_pred,y_val))\nprint(confusion_matrix(y_pred,y_val))\n#Accuracy Score\nprint('accuracy is ',accuracy_score(y_pred,y_val))",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n         0.0       0.05      0.50      0.10         2\n         1.0       0.97      0.62      0.76        48\n\n   micro avg       0.62      0.62      0.62        50\n   macro avg       0.51      0.56      0.43        50\nweighted avg       0.93      0.62      0.73        50\n\n[[ 1  1]\n [18 30]]\naccuracy is  0.62\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1311eb15f2afceed2219faeb859d0d07b7072176"
      },
      "cell_type": "markdown",
      "source": "<a id=\"53\"></a> <br>\n## 5-3 Bagging classifier \nA Bagging classifier is an ensemble **meta-estimator** that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n\nThis algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting . If samples are drawn with replacement, then the method is known as Bagging . When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces . Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches .[http://scikit-learn.org]\n<br>\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "c11c731d3db6c1c81301da85dc158cb7d324c4cb",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import BaggingClassifier\nbag_Model=BaggingClassifier()\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_val)\nprint(classification_report(y_pred,y_val))\nprint(confusion_matrix(y_pred,y_val))\n#Accuracy Score\nprint('accuracy is ',accuracy_score(y_pred,y_val))",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n         0.0       0.11      0.67      0.18         3\n         1.0       0.97      0.64      0.77        47\n\n   micro avg       0.64      0.64      0.64        50\n   macro avg       0.54      0.65      0.48        50\nweighted avg       0.92      0.64      0.73        50\n\n[[ 2  1]\n [17 30]]\naccuracy is  0.64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c0944bd32424f38906148d96f4b1e6fccfbf97a6"
      },
      "cell_type": "markdown",
      "source": "<a id=\"54\"></a> <br>\n##  5-4 AdaBoost classifier\n\nAn AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.\nThis class implements the algorithm known as **AdaBoost-SAMME** ."
    },
    {
      "metadata": {
        "_uuid": "938946ee8e017b982c4c06e193d4d13cb7d3fb5f",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import AdaBoostClassifier\nModel=AdaBoostClassifier()\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_val)\nprint(classification_report(y_pred,y_val))\nprint(confusion_matrix(y_pred,y_val))\n#Accuracy Score\nprint('accuracy is ',accuracy_score(y_pred,y_val))",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n         0.0       0.37      0.70      0.48        10\n         1.0       0.90      0.70      0.79        40\n\n   micro avg       0.70      0.70      0.70        50\n   macro avg       0.64      0.70      0.64        50\nweighted avg       0.80      0.70      0.73        50\n\n[[ 7  3]\n [12 28]]\naccuracy is  0.7\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "9d62842d12731d3eb1d6577c5b35c12c4886c708"
      },
      "cell_type": "markdown",
      "source": "<a id=\"55\"></a> <br>\n## 5-5 Gradient Boosting Classifier\nGB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions."
    },
    {
      "metadata": {
        "_uuid": "863124561c0d1b5995d0b8d3702daa7bc364d6b0",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import GradientBoostingClassifier\nModel=GradientBoostingClassifier()\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_val)\nprint(classification_report(y_pred,y_val))\nprint(confusion_matrix(y_pred,y_val))\n#Accuracy Score\nprint('accuracy is ',accuracy_score(y_pred,y_val))",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n         0.0       0.37      0.70      0.48        10\n         1.0       0.90      0.70      0.79        40\n\n   micro avg       0.70      0.70      0.70        50\n   macro avg       0.64      0.70      0.64        50\nweighted avg       0.80      0.70      0.73        50\n\n[[ 7  3]\n [12 28]]\naccuracy is  0.7\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e89b4494bd78c2d66beeba34a4e320fd8c9dae0c"
      },
      "cell_type": "markdown",
      "source": "<a id=\"56\"></a> <br>\n## 5-6 Linear Discriminant Analysis\nLinear Discriminant Analysis (discriminant_analysis.LinearDiscriminantAnalysis) and Quadratic Discriminant Analysis (discriminant_analysis.QuadraticDiscriminantAnalysis) are two classic classifiers, with, as their names suggest, a **linear and a quadratic decision surface**, respectively.\n\nThese classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no **hyperparameters** to tune."
    },
    {
      "metadata": {
        "_uuid": "0796cd9f1c902345df605b7557a9c3ff686e35a9",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nModel=LinearDiscriminantAnalysis()\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_val)\nprint(classification_report(y_pred,y_val))\nprint(confusion_matrix(y_pred,y_val))\n#Accuracy Score\nprint('accuracy is ',accuracy_score(y_pred,y_val))",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n         0.0       0.37      0.44      0.40        16\n         1.0       0.71      0.65      0.68        34\n\n   micro avg       0.58      0.58      0.58        50\n   macro avg       0.54      0.54      0.54        50\nweighted avg       0.60      0.58      0.59        50\n\n[[ 7  9]\n [12 22]]\naccuracy is  0.58\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "296137970fc94fa4a4eb4185cb5fa952b1985c57"
      },
      "cell_type": "markdown",
      "source": "<a id=\"57\"></a> <br>\n## 5-7 Quadratic Discriminant Analysis\nA classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes rule.\n\nThe model fits a **Gaussian** density to each class."
    },
    {
      "metadata": {
        "_uuid": "5f521d19f295b8e8f24f5715e93b1c45e9a6bce3",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nModel=QuadraticDiscriminantAnalysis()\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_val)\nprint(classification_report(y_pred,y_val))\nprint(confusion_matrix(y_pred,y_val))\n#Accuracy Score\nprint('accuracy is ',accuracy_score(y_pred,y_val))",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n         0.0       0.47      0.33      0.39        27\n         1.0       0.42      0.57      0.48        23\n\n   micro avg       0.44      0.44      0.44        50\n   macro avg       0.45      0.45      0.44        50\nweighted avg       0.45      0.44      0.43        50\n\n[[ 9 18]\n [10 13]]\naccuracy is  0.44\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "dfa07295f9129afeedb364eb86c678bbca9b6fa0"
      },
      "cell_type": "markdown",
      "source": "<a id=\"6\"></a> <br>\n## 6- Don't Overfit\nIn this section, we will solve the Don't Overfit problem"
    },
    {
      "metadata": {
        "_uuid": "8cda8d41f7b5a36359edc590e8b51e0eaca459bc"
      },
      "cell_type": "markdown",
      "source": "## 6-1 feature importance\nIn this section, I have used this [tutorials](https://www.kaggle.com/dansbecker/permutation-importance), that is amazing for Permutation Importance"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8844a2fb1bbfcf2664fce96f766f276aaee22677"
      },
      "cell_type": "code",
      "source": "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nrfc_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)",
      "execution_count": 134,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3971b71e9688b225fd861d9ac100d74007ee62d4"
      },
      "cell_type": "markdown",
      "source": "Here is how to calculate and show importances with the [eli5](https://eli5.readthedocs.io/en/latest/) library:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bfca97d7b0e3c8b7484ed19c0f5dd71b9265fbc1"
      },
      "cell_type": "code",
      "source": "import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rfc_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist(),top=70)",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 135,
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0222\n                \n                    &plusmn; 0.0254\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                26\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 82.05%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0190\n                \n                    &plusmn; 0.0238\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                264\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 82.05%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0190\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                116\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 82.05%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0190\n                \n                    &plusmn; 0.0238\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                163\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 84.20%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0159\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                165\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 86.48%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0127\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                217\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0381\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                33\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0324\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                260\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                117\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0254\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                282\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                94\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                91\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                207\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0324\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                82\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0095\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                233\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                196\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0431\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                214\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                266\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                133\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                208\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                173\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                145\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0063\n                \n                    &plusmn; 0.0156\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                108\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0370\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                98\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                42\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                232\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                112\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                179\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                272\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                55\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0311\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                124\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0311\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                298\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0238\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                239\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                274\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                172\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0238\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                295\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0127\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                9\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                148\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                107\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                131\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                139\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                129\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                132\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                128\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                127\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                134\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                89\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                123\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                121\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                120\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                140\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                106\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                105\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                104\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                1\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                102\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                100\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                99\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                142\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                144\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                97\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                146\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                147\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                96\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                93\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                130\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                90\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                92\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                141\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0\n                \n                    &plusmn; 0.0000\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                299\n            </td>\n        </tr>\n    \n    \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 230 more &hellip;</i>\n                </td>\n            </tr>\n        \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e9d47954d2e94b3514686a4b68d2337e7131a196"
      },
      "cell_type": "markdown",
      "source": "## Interpreting Permutation Importances\n1. The values towards the top are the most important features, and those towards the bottom matter least.\n\n1. The first number in each row shows how much model performance decreased with a random shuffling (in this case, using \"accuracy\" as the performance metric).\n\n1. Like most things in data science, there is some randomness to the exact performance change from a shuffling a column. We measure the amount of randomness in our permutation importance calculation by repeating the process with multiple shuffles. The number after the  measures how performance varied from one-reshuffling to the next. [14]"
    },
    {
      "metadata": {
        "_uuid": "ea836bc646ae66dee01c41919a5db758d84cf912"
      },
      "cell_type": "markdown",
      "source": "## Partial Dependence Plots\nWhile feature importance shows what variables most affect predictions, partial dependence plots show how a feature affects predictions.[1]"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c45947bf5dc324ff3bf9d77e393bf74fb888d9ca"
      },
      "cell_type": "code",
      "source": "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\ntree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(train_X, train_y)",
      "execution_count": 136,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "392d84211c1fd6ecdf4512f7f3b920e25232799d"
      },
      "cell_type": "markdown",
      "source": "For the sake of explanation, I use a Decision Tree which you can see below."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7150449c534fcafbf6505b6263e6760685eea143"
      },
      "cell_type": "code",
      "source": "features = [c for c in train.columns if c not in ['id', 'target']]",
      "execution_count": 137,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7ce6f581c9f0437c42c9fb6ee3051baa592dd8f"
      },
      "cell_type": "code",
      "source": "from sklearn import tree\nimport graphviz\ntree_graph = tree.export_graphviz(tree_model, out_file=None, feature_names=features)\ndisplay(graphviz.Source(tree_graph))",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<graphviz.files.Source at 0x7fd3c81d0978>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1328pt\" height=\"581pt\"\n viewBox=\"0.00 0.00 1328.00 581.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 577)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-577 1324,-577 1324,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\"><title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"882,-573 770,-573 770,-505 882,-505 882,-573\"/>\n<text text-anchor=\"middle\" x=\"826\" y=\"-557.8\" font-family=\"Times,serif\" font-size=\"14.00\">33 &lt;= &#45;0.122</text>\n<text text-anchor=\"middle\" x=\"826\" y=\"-542.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.457</text>\n<text text-anchor=\"middle\" x=\"826\" y=\"-527.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 187</text>\n<text text-anchor=\"middle\" x=\"826\" y=\"-512.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [66, 121]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\"><title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"769.5,-469 664.5,-469 664.5,-401 769.5,-401 769.5,-469\"/>\n<text text-anchor=\"middle\" x=\"717\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\">217 &lt;= 0.018</text>\n<text text-anchor=\"middle\" x=\"717\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"717\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 102</text>\n<text text-anchor=\"middle\" x=\"717\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [51, 51]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M790.611,-504.884C780.902,-495.798 770.266,-485.845 760.173,-476.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"762.278,-473.577 752.585,-469.299 757.495,-478.688 762.278,-473.577\"/>\n<text text-anchor=\"middle\" x=\"753.414\" y=\"-490.586\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\"><title>20</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1046.5,-469 941.5,-469 941.5,-401 1046.5,-401 1046.5,-469\"/>\n<text text-anchor=\"middle\" x=\"994\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\">237 &lt;= 1.058</text>\n<text text-anchor=\"middle\" x=\"994\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.291</text>\n<text text-anchor=\"middle\" x=\"994\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 85</text>\n<text text-anchor=\"middle\" x=\"994\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [15, 70]</text>\n</g>\n<!-- 0&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\"><title>0&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M880.545,-504.884C897.189,-494.778 915.599,-483.6 932.662,-473.241\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"934.713,-476.09 941.445,-467.908 931.081,-470.106 934.713,-476.09\"/>\n<text text-anchor=\"middle\" x=\"935.509\" y=\"-488.493\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\"><title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"377.5,-365 272.5,-365 272.5,-297 377.5,-297 377.5,-365\"/>\n<text text-anchor=\"middle\" x=\"325\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\">214 &lt;= &#45;1.068</text>\n<text text-anchor=\"middle\" x=\"325\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.4</text>\n<text text-anchor=\"middle\" x=\"325\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 47</text>\n<text text-anchor=\"middle\" x=\"325\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [13, 34]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M664.133,-420.244C592.332,-401.561 464.183,-368.216 387.642,-348.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"388.213,-344.832 377.654,-345.701 386.45,-351.606 388.213,-344.832\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\"><title>13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"769.5,-365 664.5,-365 664.5,-297 769.5,-297 769.5,-365\"/>\n<text text-anchor=\"middle\" x=\"717\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\">249 &lt;= 1.447</text>\n<text text-anchor=\"middle\" x=\"717\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.427</text>\n<text text-anchor=\"middle\" x=\"717\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 55</text>\n<text text-anchor=\"middle\" x=\"717\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [38, 17]</text>\n</g>\n<!-- 1&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\"><title>1&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M717,-400.884C717,-392.778 717,-383.982 717,-375.472\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"720.5,-375.299 717,-365.299 713.5,-375.299 720.5,-375.299\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\"><title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"204,-261 108,-261 108,-193 204,-193 204,-261\"/>\n<text text-anchor=\"middle\" x=\"156\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\">211 &lt;= &#45;1.532</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [6, 1]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M272.454,-298.286C253.548,-286.875 232.139,-273.954 212.881,-262.331\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.571,-259.262 204.201,-257.092 210.954,-265.255 214.571,-259.262\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\"><title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"374,-261 276,-261 276,-193 374,-193 374,-261\"/>\n<text text-anchor=\"middle\" x=\"325\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\">46 &lt;= &#45;1.133</text>\n<text text-anchor=\"middle\" x=\"325\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.289</text>\n<text text-anchor=\"middle\" x=\"325\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 40</text>\n<text text-anchor=\"middle\" x=\"325\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [7, 33]</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325,-296.884C325,-288.778 325,-279.982 325,-271.472\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"328.5,-271.299 325,-261.299 321.5,-271.299 328.5,-271.299\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\"><title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"92,-149.5 0,-149.5 0,-96.5 92,-96.5 92,-149.5\"/>\n<text text-anchor=\"middle\" x=\"46\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"46\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"46\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M120.286,-192.884C107.714,-181.226 93.6026,-168.141 81.083,-156.532\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"83.234,-153.753 73.5215,-149.52 78.4744,-158.886 83.234,-153.753\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\"><title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"202,-149.5 110,-149.5 110,-96.5 202,-96.5 202,-149.5\"/>\n<text text-anchor=\"middle\" x=\"156\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [6, 0]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M156,-192.884C156,-182.326 156,-170.597 156,-159.854\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"159.5,-159.52 156,-149.52 152.5,-159.52 159.5,-159.52\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\"><title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"312,-157 220,-157 220,-89 312,-89 312,-157\"/>\n<text text-anchor=\"middle\" x=\"266\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">276 &lt;= &#45;1.0</text>\n<text text-anchor=\"middle\" x=\"266\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"middle\" x=\"266\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"266\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M305.844,-192.884C300.898,-184.332 295.508,-175.013 290.336,-166.072\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293.298,-164.203 285.261,-157.299 287.239,-167.708 293.298,-164.203\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\"><title>10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"428,-157 330,-157 330,-89 428,-89 428,-157\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">189 &lt;= 1.232</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.157</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [3, 32]</text>\n</g>\n<!-- 6&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\"><title>6&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M342.532,-192.884C347.012,-184.422 351.89,-175.207 356.579,-166.352\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"359.785,-167.775 361.371,-157.299 353.599,-164.5 359.785,-167.775\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\"><title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"202,-53 110,-53 110,-0 202,-0 202,-53\"/>\n<text text-anchor=\"middle\" x=\"156\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"156\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M227.527,-88.9485C216.559,-79.526 204.625,-69.2731 193.703,-59.8906\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"195.824,-57.0983 185.958,-53.2367 191.263,-62.408 195.824,-57.0983\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\"><title>9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"312,-53 220,-53 220,-0 312,-0 312,-53\"/>\n<text text-anchor=\"middle\" x=\"266\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"266\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"266\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M266,-88.9485C266,-80.7153 266,-71.848 266,-63.4814\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"269.5,-63.2367 266,-53.2367 262.5,-63.2367 269.5,-63.2367\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\"><title>11</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"428,-53 330,-53 330,-0 428,-0 428,-53\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.059</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 32]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M379,-88.9485C379,-80.7153 379,-71.848 379,-63.4814\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"382.5,-63.2367 379,-53.2367 375.5,-63.2367 382.5,-63.2367\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\"><title>12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"538,-53 446,-53 446,-0 538,-0 538,-53\"/>\n<text text-anchor=\"middle\" x=\"492\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"492\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"492\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\"><title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M418.522,-88.9485C429.789,-79.526 442.049,-69.2731 453.268,-59.8906\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"455.799,-62.3368 461.225,-53.2367 451.308,-56.967 455.799,-62.3368\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\"><title>14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"710.5,-261 605.5,-261 605.5,-193 710.5,-193 710.5,-261\"/>\n<text text-anchor=\"middle\" x=\"658\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\">250 &lt;= 1.681</text>\n<text text-anchor=\"middle\" x=\"658\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.348</text>\n<text text-anchor=\"middle\" x=\"658\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 49</text>\n<text text-anchor=\"middle\" x=\"658\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [38, 11]</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M697.844,-296.884C692.898,-288.332 687.508,-279.013 682.336,-270.072\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"685.298,-268.203 677.261,-261.299 679.239,-271.708 685.298,-268.203\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\"><title>19</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"821,-253.5 729,-253.5 729,-200.5 821,-200.5 821,-253.5\"/>\n<text text-anchor=\"middle\" x=\"775\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"775\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"775\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 13&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\"><title>13&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M735.831,-296.884C742.085,-285.886 749.061,-273.617 755.373,-262.517\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"758.588,-263.943 760.489,-253.52 752.503,-260.483 758.588,-263.943\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\"><title>15</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"654,-157 556,-157 556,-89 654,-89 654,-157\"/>\n<text text-anchor=\"middle\" x=\"605\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">47 &lt;= 0.962</text>\n<text text-anchor=\"middle\" x=\"605\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.206</text>\n<text text-anchor=\"middle\" x=\"605\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 43</text>\n<text text-anchor=\"middle\" x=\"605\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [38, 5]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\"><title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M640.792,-192.884C636.395,-184.422 631.608,-175.207 627.006,-166.352\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"630.019,-164.559 622.303,-157.299 623.808,-167.787 630.019,-164.559\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\"><title>18</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"764,-149.5 672,-149.5 672,-96.5 764,-96.5 764,-149.5\"/>\n<text text-anchor=\"middle\" x=\"718\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"718\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"718\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 14&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\"><title>14&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M677.48,-192.884C684.014,-181.776 691.311,-169.372 697.892,-158.184\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"700.935,-159.914 702.988,-149.52 694.901,-156.365 700.935,-159.914\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\"><title>16</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"654,-53 556,-53 556,-0 654,-0 654,-53\"/>\n<text text-anchor=\"middle\" x=\"605\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.051</text>\n<text text-anchor=\"middle\" x=\"605\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 38</text>\n<text text-anchor=\"middle\" x=\"605\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [37, 1]</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M605,-88.9485C605,-80.7153 605,-71.848 605,-63.4814\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"608.5,-63.2367 605,-53.2367 601.5,-63.2367 608.5,-63.2367\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\"><title>17</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"764,-53 672,-53 672,-0 764,-0 764,-53\"/>\n<text text-anchor=\"middle\" x=\"718\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"middle\" x=\"718\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"718\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 4]</text>\n</g>\n<!-- 15&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\"><title>15&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M644.522,-88.9485C655.789,-79.526 668.049,-69.2731 679.268,-59.8906\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"681.799,-62.3368 687.225,-53.2367 677.308,-56.967 681.799,-62.3368\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\"><title>21</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1046.5,-365 941.5,-365 941.5,-297 1046.5,-297 1046.5,-365\"/>\n<text text-anchor=\"middle\" x=\"994\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\">220 &lt;= 1.071</text>\n<text text-anchor=\"middle\" x=\"994\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.224</text>\n<text text-anchor=\"middle\" x=\"994\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 78</text>\n<text text-anchor=\"middle\" x=\"994\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [10, 68]</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\"><title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M994,-400.884C994,-392.778 994,-383.982 994,-375.472\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"997.5,-375.299 994,-365.299 990.5,-375.299 997.5,-375.299\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\"><title>30</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1210,-365 1118,-365 1118,-297 1210,-297 1210,-365\"/>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\">210 &lt;= 0.875</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [5, 2]</text>\n</g>\n<!-- 20&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\"><title>20&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1046.86,-402.286C1066.64,-390.416 1089.15,-376.912 1109.11,-364.935\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1111.01,-367.874 1117.79,-359.728 1107.41,-361.872 1111.01,-367.874\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\"><title>22</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"990,-261 892,-261 892,-193 990,-193 990,-261\"/>\n<text text-anchor=\"middle\" x=\"941\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\">179 &lt;= 1.794</text>\n<text text-anchor=\"middle\" x=\"941\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.151</text>\n<text text-anchor=\"middle\" x=\"941\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 73</text>\n<text text-anchor=\"middle\" x=\"941\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [6, 67]</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\"><title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M976.792,-296.884C972.395,-288.422 967.608,-279.207 963.006,-270.352\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"966.019,-268.559 958.303,-261.299 959.808,-271.787 966.019,-268.559\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\"><title>27</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1100,-261 1008,-261 1008,-193 1100,-193 1100,-261\"/>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\">99 &lt;= 1.483</text>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 21&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\"><title>21&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1013.48,-296.884C1018.51,-288.332 1023.99,-279.013 1029.25,-270.072\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1032.36,-271.693 1034.41,-261.299 1026.33,-268.144 1032.36,-271.693\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\"><title>23</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"880,-157 782,-157 782,-89 880,-89 880,-157\"/>\n<text text-anchor=\"middle\" x=\"831\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">147 &lt;= 1.71</text>\n<text text-anchor=\"middle\" x=\"831\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.106</text>\n<text text-anchor=\"middle\" x=\"831\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 71</text>\n<text text-anchor=\"middle\" x=\"831\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 67]</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\"><title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M905.286,-192.884C895.392,-183.709 884.544,-173.65 874.27,-164.123\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"876.624,-161.532 866.911,-157.299 871.864,-166.665 876.624,-161.532\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\"><title>26</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"990,-149.5 898,-149.5 898,-96.5 990,-96.5 990,-149.5\"/>\n<text text-anchor=\"middle\" x=\"944\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"944\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"944\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 22&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\"><title>22&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M941.974,-192.884C942.288,-182.216 942.637,-170.352 942.955,-159.519\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"946.454,-159.619 943.249,-149.52 939.457,-159.413 946.454,-159.619\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\"><title>24</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"880,-53 782,-53 782,-0 880,-0 880,-53\"/>\n<text text-anchor=\"middle\" x=\"831\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.057</text>\n<text text-anchor=\"middle\" x=\"831\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 68</text>\n<text text-anchor=\"middle\" x=\"831\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 66]</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\"><title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M831,-88.9485C831,-80.7153 831,-71.848 831,-63.4814\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"834.5,-63.2367 831,-53.2367 827.5,-63.2367 834.5,-63.2367\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\"><title>25</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"990,-53 898,-53 898,-0 990,-0 990,-53\"/>\n<text text-anchor=\"middle\" x=\"944\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"middle\" x=\"944\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"944\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\"><title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M870.522,-88.9485C881.789,-79.526 894.049,-69.2731 905.268,-59.8906\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"907.799,-62.3368 913.225,-53.2367 903.308,-56.967 907.799,-62.3368\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\"><title>28</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1100,-149.5 1008,-149.5 1008,-96.5 1100,-96.5 1100,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"1054\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 27&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\"><title>27&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1054,-192.884C1054,-182.326 1054,-170.597 1054,-159.854\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1057.5,-159.52 1054,-149.52 1050.5,-159.52 1057.5,-159.52\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\"><title>29</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1210,-149.5 1118,-149.5 1118,-96.5 1210,-96.5 1210,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 27&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\"><title>27&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1089.71,-192.884C1102.29,-181.226 1116.4,-168.141 1128.92,-156.532\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1131.53,-158.886 1136.48,-149.52 1126.77,-153.753 1131.53,-158.886\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\"><title>31</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1210,-253.5 1118,-253.5 1118,-200.5 1210,-200.5 1210,-253.5\"/>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1164\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 30&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\"><title>30&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1164,-296.884C1164,-286.326 1164,-274.597 1164,-263.854\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1167.5,-263.52 1164,-253.52 1160.5,-263.52 1167.5,-263.52\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\"><title>32</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1320,-253.5 1228,-253.5 1228,-200.5 1320,-200.5 1320,-253.5\"/>\n<text text-anchor=\"middle\" x=\"1274\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1274\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1274\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 30&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\"><title>30&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1199.71,-296.884C1212.29,-285.226 1226.4,-272.141 1238.92,-260.532\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1241.53,-262.886 1246.48,-253.52 1236.77,-257.753 1241.53,-262.886\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2bcd6a4b3e0116de480b9edee7b632e6ede15b06"
      },
      "cell_type": "code",
      "source": "from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\n# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=tree_model, dataset=val_X, model_features=features, feature='26')\n\n# plot it\npdp.pdp_plot(pdp_goals, '26')\nplt.show()",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1080x684 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1dd74d524cd65fee7974bf435b8be9c399e2045d"
      },
      "cell_type": "code",
      "source": "# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=tree_model, dataset=val_X, model_features=features, feature='264')\n\n# plot it\npdp.pdp_plot(pdp_goals, '264')\nplt.show()",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1080x684 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "afc2a360fedd783e5e9d7bbc975c9c6f06a2ee72"
      },
      "cell_type": "markdown",
      "source": "<a id=\"7\"></a> <br>\n# 7-Conclusion\nThe Ensemble Learning generally prevents the **overfit**  and in many cases produces better results than other algorithms.\nThe success of the ensemble system is based on the variety of classifiers that make up it. If all classifiers provide the same output, a possible mistaken correction is not possible. So there should be different errors on different samples. If any classifier delivers a different error, then you can reduce the overall error by combining them strategically. Therefore, such a set of classifiers should be diverse. This variety can be achieved in a variety of ways.\n\nand is not completed yet!!!\n<br>\n[go to top](#top)"
    },
    {
      "metadata": {
        "_uuid": "b132163ee07917a0ab100b93f6ed5545ce0de45d"
      },
      "cell_type": "markdown",
      "source": "you can follow me on:\n> ###### [ GitHub](https://github.com/mjbahmani)\n> ###### [Kaggle](https://www.kaggle.com/mjbahmani/)\n\n  **I hope you find this kernel helpful and some <font color='red'> UPVOTES</font> would be very much appreciated**\n "
    },
    {
      "metadata": {
        "_uuid": "5719a5ba111b65b20b53d538281ac773eb14471a"
      },
      "cell_type": "markdown",
      "source": "<a id=\"8\"></a> <br>\n# 8-References & Credits"
    },
    {
      "metadata": {
        "_uuid": "aab5b3d8cb417250dc6baa081a579106900effba"
      },
      "cell_type": "markdown",
      "source": "1. [datacamp](https://www.datacamp.com/community/tutorials/xgboost-in-python)\n1. [Xgboost presentation](https://www.oreilly.com/library/view/data-science-from/9781491901410/ch04.html)\n1. [machinelearningmastery](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)\n1. [analyticsvidhya](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)\n1. [Github](https://github.com/mjbahmani)\n1. [analyticsvidhya](https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/)\n1. [ensemble-learning-python](https://www.datacamp.com/community/tutorials/ensemble-learning-python)\n1. [image-header-reference](https://data-science-blog.com/blog/2017/12/03/ensemble-learning/)\n1. [scholarpedia](http://www.scholarpedia.org/article/Ensemble_learning)\n1. [toptal](https://www.toptal.com/machine-learning/ensemble-methods-machine-learning)\n1. [quantdare](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/)\n1. [towardsdatascience](https://towardsdatascience.com/ensemble-methods-in-machine-learning-what-are-they-and-why-use-them-68ec3f9fef5f)\n1. [scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html)\n1. [permutation-importance](https://www.kaggle.com/dansbecker/permutation-importance)\n1. [partial-plots](https://www.kaggle.com/dansbecker/partial-plots)"
    },
    {
      "metadata": {
        "_uuid": "905a9a2ba1f3acee4e8f85df99cfb0cc9c924b28"
      },
      "cell_type": "markdown",
      "source": "Go to first step: [**Course Home Page**](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\nGo to next step : [**Mathematics and Linear Algebra**](https://www.kaggle.com/mjbahmani/linear-algebra-for-data-scientists)"
    },
    {
      "metadata": {
        "_uuid": "1b0470ef26dff78a8f9b1ebac1da58fe7d562e76"
      },
      "cell_type": "markdown",
      "source": "## Not Completed yet!!!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}